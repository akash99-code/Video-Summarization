{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62efed64-9c9e-4aea-bdd3-ee0ce51a0dfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22b9d9-432f-4ce9-ab1a-363d5d77bb60",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa16b01-cf5d-4004-8390-7deda06173ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.models as tmodels\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7f7bc-dbd6-4708-b9f9-032a6edcb440",
   "metadata": {},
   "source": [
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a287ef-4279-466d-8dca-f9316a783d56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXTRACT_FREQUENCY = 15\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "args = {'use_cpu':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948adf19-38ff-4d7c-9f9d-af81c2aa603a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0fbc53-1fad-482a-9d9b-28b790cf6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets_path='../data'\n",
    "public_dataset_path=datasets_path+'/Public datasets'\n",
    "tvsum_data = public_dataset_path+'/ydata-tvsum50-v1_1'\n",
    "summe_data = public_dataset_path+'/SUMMe'\n",
    "custom_data = datasets_path+'/Custom data'\n",
    "\n",
    "\n",
    "features_path = 'extracted_features'\n",
    "normalFt_path = features_path+'/normal'\n",
    "hashbasedFt_path = features_path+'/hashbased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b759493-a70b-461b-bba3-7f734cb83437",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) GoogLeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17d2d72-8964-41f1-b15c-10495a8cc3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Msc 2\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Msc 2\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "googlenet = tmodels.googlenet(pretrained=True)\n",
    "googlenet = torch.nn.Sequential(*list(googlenet.children())[:-2])\n",
    "# googlenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd275c9-e68f-4fe9-839c-6ed757f5e2b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() and not use_cpu else 'cpu'\n",
    "googlenet = googlenet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ccc9b-e6a9-4044-ad90-53e9596460fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) Frame preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ebc6c7-4bdc-4d45-9f2c-25a2c97f4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def preprocess(frame):\n",
    "    tr = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # BGR to RGB\n",
    "    im = Image.fromarray(im) # cv2 to PIL\n",
    "    im = tr(im)\n",
    "    fr = np.array(im)\n",
    "    \n",
    "    return fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07485476-6699-4c1c-8122-6315593c579b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extraction Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd3bb0-f2e6-45c3-b537-2544a8991711",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### )) Hashed based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdfd4712-fb8b-4536-940c-0c6213be87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhash(img):\n",
    "    img=cv2.resize(img,(9,8),interpolation=cv2.INTER_CUBIC)\n",
    "    # gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    dhash_str = ''\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if gray[i, j] > gray[i, j + 1]:\n",
    "                dhash_str = dhash_str + '1'\n",
    "            else:\n",
    "                dhash_str = dhash_str + '0'\n",
    "    result = ''\n",
    "    for i in range(0, len(dhash_str), 4):\n",
    "        result += ''.join('%x' % int(dhash_str[i: i + 4], 2))\n",
    "    # print(result)\n",
    "    return result\n",
    "\n",
    "def hamming(s1, s2):\n",
    "    assert len(s1) == len(s2)\n",
    "    return sum([ch1 != ch2 for ch1, ch2 in zip(s1, s2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb7dde1-c977-44e5-9de3-4a3bba5f1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_gen_features(path, threshold):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames=[]\n",
    "    video_features = []\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    count = 0\n",
    "    skip_count = 0\n",
    "    \n",
    "    nframes = frame_count//EXTRACT_FREQUENCY * EXTRACT_FREQUENCY\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        base = None\n",
    "        hash1 = None\n",
    "        while cap.isOpened():\n",
    "            # Capture frame-by-frame\n",
    "            ret, fr = cap.read()\n",
    "            if ret is False:\n",
    "                break\n",
    "            count += 1\n",
    "            \n",
    "            frame = preprocess(fr)\n",
    "\n",
    "            if count % EXTRACT_FREQUENCY == 0:\n",
    "                hash2=dhash(fr)\n",
    "                if hash1 is not None:\n",
    "                    dist = hamming(hash1,hash2)\n",
    "                if base is None or dist > threshold:\n",
    "                    base = fr\n",
    "                    hash1 = hash2\n",
    "                    frames.append(frame)\n",
    "                else:\n",
    "                    skip_count += 1\n",
    "                    frames.append(frame)\n",
    "                    \n",
    "                if (len(frames) == BATCH_SIZE) or (count == nframes and len(frames) > 0):\n",
    "                    batch = np.array(frames)\n",
    "                    if args['use_cpu']:\n",
    "                        variable = Variable(torch.from_numpy(batch).float())\n",
    "                        feature = googlenet(variable).detach().numpy()\n",
    "                    else:\n",
    "                        variable = Variable(torch.from_numpy(batch).float()).cuda()\n",
    "                        feature = googlenet(variable).cpu().detach().numpy()\n",
    "                        \n",
    "                    video_features.extend(feature)\n",
    "                    frames.clear()\n",
    "                    \n",
    "\n",
    "    cap.release()\n",
    "    video_features = np.squeeze(np.array(video_features))\n",
    "    return video_features, frame_count, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57c5f9-469a-40fc-87a7-d6280badbfca",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) Normal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c78097-3883-4b4d-82c7-ebb6dae9363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    count = 0\n",
    "    frames = []\n",
    "    video_features = []\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    nframes = frame_count//EXTRACT_FREQUENCY * EXTRACT_FREQUENCY\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, fr = cap.read()\n",
    "            if ret is False:\n",
    "                break\n",
    "\n",
    "            fr = preprocess(fr)\n",
    "            \n",
    "            count += 1\n",
    "            if count % EXTRACT_FREQUENCY == 0:\n",
    "                # frames.append(np.rollaxis(fr, 2))\n",
    "                frames.append(fr)\n",
    "                \n",
    "                \n",
    "            if (len(frames) == BATCH_SIZE) or (count == nframes and len(frames) > 0):\n",
    "                batch = np.array(frames)\n",
    "                # print(batch.shape)\n",
    "                if args['use_cpu']:\n",
    "                    variable = Variable(torch.from_numpy(batch).float())\n",
    "                    feature = googlenet(variable).detach().numpy()\n",
    "                else:\n",
    "                    variable = Variable(torch.from_numpy(batch).float()).cuda()\n",
    "                    feature = googlenet(variable).cpu().detach().numpy()\n",
    "                video_features.extend(feature)\n",
    "                frames.clear()\n",
    "    \n",
    "            \n",
    "    cap.release()\n",
    "\n",
    "    video_features = np.squeeze(np.array(video_features))\n",
    "    return video_features, frame_count, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05431f38-86ae-4c03-8707-c049afd9280f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) Feature extraction and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966caa46-627b-4ab7-9ca2-bc9d6a48493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(videos_path, h5output_path, method=None, names=None):\n",
    "    h5_file = h5output_path\n",
    "    # st = time()\n",
    "\n",
    "    with h5py.File(h5_file, 'w') as f:\n",
    "        files = os.listdir(videos_path)\n",
    "        cnt = 0\n",
    "        \n",
    "        pbar = tqdm(total = len(files), position=0, leave=True)\n",
    "        for file in files:\n",
    "            cnt += 1\n",
    "            path = videos_path + \"/\" + file\n",
    "            \n",
    "            if method == 'hashbased':\n",
    "                video_features, fcnt, fps = hash_gen_features(path,4.0)\n",
    "            else:\n",
    "                video_features, fcnt, fps = gen_features(path)\n",
    "\n",
    "            video_length = fcnt/fps\n",
    "            \n",
    "            if names:\n",
    "                video_ = 'video_'+str(names.index(file.split(\".\")[0])+1)\n",
    "            else:\n",
    "                video_ = 'video_'+str(cnt)\n",
    "\n",
    "            print(cnt,'.', video_, \"no. of frames=\", fcnt, \"Output dimension=\", video_features.shape)\n",
    "\n",
    "            f.create_dataset(video_ + '/n_frames', data=int(fcnt))\n",
    "            f.create_dataset(video_ + '/fps', data=int(fps))\n",
    "            f.create_dataset(video_ + '/features', data=video_features)\n",
    "            picks = np.arange(0, video_features.shape[0]) * EXTRACT_FREQUENCY\n",
    "            f.create_dataset(video_ + '/picks', data=picks)\n",
    "            f.create_dataset(video_+'/duration', data=video_length)\n",
    "            f.create_dataset(video_+'/video_name', data=str(file))\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140196e6-439b-4c4a-8e02-b44be397518e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TVSum feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4b679-3be4-4b91-83ec-095094a74188",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) TVSumm info"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6c94bbc-b6b9-4b8d-9419-a0f8e8281c16",
   "metadata": {},
   "source": [
    "tvsum_info=pd.read_csv(tvsum_data+'/data/ydata-tvsum50-info.tsv',sep='\\t')\n",
    "tvsum_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761d004-7208-4ad1-98c2-87e15c4d9eda",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) Videos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "186300e2-4880-4587-a6df-bf51eb327db6",
   "metadata": {},
   "source": [
    "os.listdir(tvsum_data+'/video')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b942965-d4f9-4988-82b6-b60a6750b657",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### )) Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18e96c2c-3450-4296-94a8-d1e6c1f51864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:58<47:32, 58.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . video_50 no. of frames= 6912.0 Output dimension= (460, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:28<33:16, 41.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 . video_13 no. of frames= 3532.0 Output dimension= (235, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [02:16<35:08, 44.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 . video_19 no. of frames= 5742.0 Output dimension= (382, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [02:44<29:09, 38.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 . video_14 no. of frames= 4853.0 Output dimension= (323, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [03:19<27:50, 37.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 . video_30 no. of frames= 4005.0 Output dimension= (267, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [03:50<25:27, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 . video_26 no. of frames= 3312.0 Output dimension= (220, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [04:32<26:37, 37.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 . video_2 no. of frames= 4688.0 Output dimension= (312, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [05:06<25:28, 36.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 . video_10 no. of frames= 3995.0 Output dimension= (266, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [06:13<31:23, 45.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 . video_1 no. of frames= 10597.0 Output dimension= (706, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [07:01<31:03, 46.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 . video_22 no. of frames= 5661.0 Output dimension= (377, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [08:56<43:45, 67.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 . video_12 no. of frames= 13511.0 Output dimension= (900, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [09:27<35:43, 56.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 . video_34 no. of frames= 3705.0 Output dimension= (247, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [11:17<44:50, 72.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 . video_21 no. of frames= 19406.0 Output dimension= (1293, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [13:36<55:30, 92.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 . video_46 no. of frames= 15307.0 Output dimension= (1020, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [14:00<42:02, 72.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 . video_38 no. of frames= 2941.0 Output dimension= (196, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [14:43<35:50, 63.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 . video_43 no. of frames= 4931.0 Output dimension= (328, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [15:20<30:28, 55.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 . video_42 no. of frames= 5939.0 Output dimension= (395, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [16:58<36:16, 68.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 . video_29 no. of frames= 17527.0 Output dimension= (1168, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [17:34<30:14, 58.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 . video_24 no. of frames= 4356.0 Output dimension= (290, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [18:37<29:55, 59.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 . video_4 no. of frames= 7210.0 Output dimension= (480, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [19:26<27:23, 56.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 . video_17 no. of frames= 5846.0 Output dimension= (389, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [20:48<29:57, 64.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 . video_6 no. of frames= 9671.0 Output dimension= (644, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [21:28<25:35, 56.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 . video_11 no. of frames= 4700.0 Output dimension= (313, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [21:49<19:57, 46.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 . video_45 no. of frames= 2500.0 Output dimension= (166, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [23:48<28:22, 68.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 . video_3 no. of frames= 14019.0 Output dimension= (934, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [24:38<25:05, 62.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 . video_49 no. of frames= 5971.0 Output dimension= (398, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [25:16<21:05, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 . video_44 no. of frames= 4304.0 Output dimension= (286, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [25:38<16:35, 45.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 . video_32 no. of frames= 3802.0 Output dimension= (253, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [26:14<14:50, 42.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 . video_48 no. of frames= 3896.0 Output dimension= (259, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [27:10<15:33, 46.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 . video_20 no. of frames= 6241.0 Output dimension= (416, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [27:51<14:12, 44.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 . video_47 no. of frames= 4740.0 Output dimension= (316, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [29:27<18:05, 60.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 . video_40 no. of frames= 11414.0 Output dimension= (760, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [30:23<16:39, 58.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 . video_25 no. of frames= 6580.0 Output dimension= (438, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [31:34<16:39, 62.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 . video_41 no. of frames= 8073.0 Output dimension= (538, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [33:08<17:58, 71.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 . video_27 no. of frames= 10917.0 Output dimension= (727, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [33:30<13:19, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 . video_39 no. of frames= 4166.0 Output dimension= (277, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [34:08<11:08, 51.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 . video_7 no. of frames= 4468.0 Output dimension= (297, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [34:43<09:17, 46.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 . video_37 no. of frames= 4009.0 Output dimension= (267, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [35:43<09:13, 50.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 . video_8 no. of frames= 9870.0 Output dimension= (658, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [36:32<08:21, 50.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 . video_31 no. of frames= 5412.0 Output dimension= (360, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [37:58<09:08, 60.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 . video_16 no. of frames= 9535.0 Output dimension= (635, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [39:07<08:26, 63.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 . video_36 no. of frames= 7959.0 Output dimension= (530, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [39:57<06:54, 59.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 . video_23 no. of frames= 5631.0 Output dimension= (375, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [41:53<07:38, 76.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 . video_33 no. of frames= 13365.0 Output dimension= (891, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [42:55<05:59, 71.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 . video_9 no. of frames= 7010.0 Output dimension= (467, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [43:19<03:50, 57.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 . video_15 no. of frames= 4324.0 Output dimension= (288, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [43:48<02:26, 48.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 . video_5 no. of frames= 3327.0 Output dimension= (221, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [45:11<01:58, 59.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 . video_18 no. of frames= 9731.0 Output dimension= (648, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [46:21<01:02, 62.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 . video_28 no. of frames= 8281.0 Output dimension= (552, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [46:59<00:00, 56.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 . video_35 no. of frames= 4463.0 Output dimension= (297, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# vnames = tvsum_info['video_id'].tolist()\n",
    "# extract_features(videos_path=tvsum_data+'/video', h5output_path=normalFt_path+'/TVSum.h5', names=vnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b87c3a-767a-4f11-b885-2a63051ce662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract_features(videos_path=tvsum_data+'/video', h5output_path=hashbasedFt_path+'/TVSum.h5',method='hashbased', names=vnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014234c3-be85-41aa-9ab5-b3002789b142",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218691a-6b96-4eb6-a3cd-0dcc42cc628e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### *H5File metadata*"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fddaf3d9-6eda-40b6-82a7-3148cc2b0a0e",
   "metadata": {},
   "source": [
    "/key\n",
    "    -/features                 2D-array with shape (n_steps, feature-dimension)\n",
    "    /gtscore                  1D-array with shape (n_steps), stores ground truth improtance score\n",
    "    /user_summary             2D-array with shape (num_users, n_frames), each row is a binary vector\n",
    "    /change_points            2D-array with shape (num_segments, 2), each row stores indices of a segment\n",
    "    /n_frame_per_seg          1D-array with shape (num_segments), indicates number of frames in each segment\n",
    "    -/n_frames                 number of frames in original video\n",
    "    -/picks                    posotions of subsampled frames in original video\n",
    "    /n_steps                  number of subsampled frames\n",
    "    /gtsummary                1D-array with shape (n_steps), ground truth summary provided by user\n",
    "    /video_name (optional)    original video name, only available for SumMe dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
