{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075f1a79-7099-4fc0-9a10-c730596635d7",
   "metadata": {},
   "source": [
    "## Annotated Summary processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93c7d97-59dd-4b64-8935-bbe505b14df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from ortools.algorithms import pywrapknapsack_solver\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d924a530-e4f4-4b50-8771-41892d67cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path='../data'\n",
    "public_dataset_path=datasets_path+'/Public datasets'\n",
    "tvsum_data = public_dataset_path+'/ydata-tvsum50-v1_1'\n",
    "summe_data = public_dataset_path+'/SUMMe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f3c1581-d085-4040-8201-8af2f15fce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FREQUENCY = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c84701-841b-4897-99c6-cf1639244255",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def videoname_map(name, info_df):\n",
    "    if info_df is None:\n",
    "        return name\n",
    "    key = info_df[info_df['video_id'] == name].index[0]\n",
    "    key='video_'+str(key)\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8d2cb-b697-43fe-b7cf-147c14c97607",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser.add_argument('-d', '--dataset', type=str, required=True, help=\"path to h5 dataset (required)\")\n",
    "parser.add_argument('-s', '--split', type=str, required=True, help=\"path to split file (required)\")\n",
    "# parser.add_argument('--split-id', type=int, default=4, help=\"split index (default: 0)\")\n",
    "parser.add_argument('-m', '--metric', type=str, required=True, choices=['tvsum', 'summe'],\n",
    "                    help=\"evaluation metric ['tvsum', 'summe']\")\n",
    "# Model options\n",
    "parser.add_argument('--input-dim', type=int, default=1024, help=\"input dimension (default: 1024)\")\n",
    "parser.add_argument('--hidden-dim', type=int, default=256, help=\"hidden unit dimension of DSN (default: 256)\")\n",
    "parser.add_argument('--num-layers', type=int, default=1, help=\"number of RNN layers (default: 1)\")\n",
    "parser.add_argument('--rnn-cell', type=str, default='lstm', help=\"RNN cell type (default: lstm)\")\n",
    "# parser.add_argument('--dropout', type=float, default=0.0, help=\"dropout rate\")\n",
    "\n",
    "# Optimization options\n",
    "parser.add_argument('--lr', type=float, default=1e-05, help=\"learning rate (default: 1e-05)\")\n",
    "parser.add_argument('--weight-decay', type=float, default=1e-05, help=\"weight decay rate (default: 1e-05)\")\n",
    "parser.add_argument('--max-epoch', type=int, default=60, help=\"maximum epoch for training (default: 60)\")\n",
    "parser.add_argument('--stepsize', type=int, default=30, help=\"how many steps to decay learning rate (default: 30)\")\n",
    "parser.add_argument('--gamma', type=float, default=0.1, help=\"learning rate decay (default: 0.1)\")\n",
    "parser.add_argument('--num-episode', type=int, default=5, help=\"number of episodes (default: 5)\")\n",
    "parser.add_argument('--beta', type=float, default=0.01, help=\"weight for summary length penalty term (default: 0.01)\")\n",
    "# Misc\n",
    "parser.add_argument('--seed', type=int, default=1, help=\"random seed (default: 1)\")\n",
    "parser.add_argument('--gpu', type=str, default='0', help=\"which gpu devices to use\")\n",
    "parser.add_argument('--use-cpu', action='store_true', help=\"use cpu device\")\n",
    "parser.add_argument('--evaluate', action='store_true', help=\"whether to do evaluation only\")\n",
    "parser.add_argument('--save-dir', type=str, help=\"path to save output\")\n",
    "parser.add_argument('--resume', type=str, default='', help=\"path to resume file\")\n",
    "parser.add_argument('--verbose', action='store_true', help=\"whether to show detailed test results\")\n",
    "# parser.add_argument('--save-results', default=True, help=\"whether to save output results\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if args.use_cpu: use_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f216b1e-14fa-4593-83e9-a20fa1f72ca3",
   "metadata": {},
   "source": [
    "#### )) Knapsnack algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "752e02f2-e7a3-4e44-94c0-adb0eabe2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_ortools(values, weights, items, capacity ):\n",
    "    scale = 1000\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    values = (values * scale).astype(np.int32)\n",
    "    weights = (weights).astype(np.int32)\n",
    "    capacity = capacity\n",
    "    osolver = pywrapknapsack_solver.KnapsackSolver(pywrapknapsack_solver.KnapsackSolver.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER,'test')\n",
    "    osolver.Init(values.tolist(), [weights.tolist()], [capacity])\n",
    "    computed_value = osolver.Solve()\n",
    "    packed_items = [x for x in range(0, len(weights))\n",
    "                    if osolver.BestSolutionContains(x)]\n",
    "\n",
    "    return packed_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1456d61-07ca-4134-b4ba-7f3df1753875",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def knapsack_dp(values,weights,n_items,capacity,return_all=False):\n",
    "    # check_inputs(values,weights,n_items,capacity)\n",
    "    \n",
    "    assert(isinstance(values,list))\n",
    "    assert(isinstance(weights,list))\n",
    "    assert(isinstance(n_items,int))\n",
    "    assert(isinstance(capacity,int))\n",
    "    # check value type\n",
    "    assert(all(isinstance(val,int) or isinstance(val,float) for val in values))\n",
    "    assert(all(isinstance(val,int) for val in weights))\n",
    "    # check validity of value\n",
    "    assert(all(val >= 0 for val in weights))\n",
    "    assert(n_items > 0)\n",
    "    assert(capacity > 0)\n",
    "\n",
    "    table = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
    "    keep = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
    "\n",
    "    for i in range(1,n_items+1):\n",
    "        for w in range(0,capacity+1):\n",
    "            wi = weights[i-1] # weight of current item\n",
    "            vi = values[i-1] # value of current item\n",
    "            if (wi <= w) and (vi + table[i-1,w-wi] > table[i-1,w]):\n",
    "                table[i,w] = vi + table[i-1,w-wi]\n",
    "                keep[i,w] = 1\n",
    "            else:\n",
    "                table[i,w] = table[i-1,w]\n",
    "\n",
    "    picks = []\n",
    "    K = capacity\n",
    "\n",
    "    for i in range(n_items,0,-1):\n",
    "        if keep[i,K] == 1:\n",
    "            picks.append(i)\n",
    "            K -= weights[i-1]\n",
    "\n",
    "    picks.sort()\n",
    "    picks = [x-1 for x in picks] # change to 0-index\n",
    "\n",
    "    if return_all:\n",
    "        max_val = table[n_items,capacity]\n",
    "        return picks,max_val\n",
    "    return picks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aad890-f032-4442-8172-c568620b852e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### )) User Summary Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8658193f-7518-4ebc-8735-6a05b08a63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_summary(frame_scores, cps, n_frames, nfps, proportion=0.15, method='knapsack'):\n",
    "    \"\"\"Generate keyshot-based video summary i.e. a binary vector.\n",
    "    Args:\n",
    "    ---------------------------------------------\n",
    "    - frame_scores: importance scores by users.\n",
    "    - cps: change points, 2D matrix, each row contains a segment.\n",
    "    - n_frames: original number of frames.\n",
    "    - nfps: number of frames per segment.\n",
    "    - proportion: length of video summary (compared to original video length).\n",
    "    - method: defines how shots are selected, ['knapsack', 'rank'].\n",
    "    \"\"\"\n",
    "    n_segs = cps.shape[0]\n",
    "\n",
    "    seg_score = []\n",
    "    for seg_idx in range(n_segs):\n",
    "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
    "        # print(start,end)\n",
    "        scores = frame_scores[start:end]\n",
    "        seg_score.append(float(scores.mean()))\n",
    "\n",
    "    limits = int(math.floor(n_frames * proportion))\n",
    "\n",
    "    if method == 'knapsack':\n",
    "        # picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
    "        picks = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
    "    elif method == 'rank':\n",
    "        order = np.argsort(seg_score)[::-1].tolist()\n",
    "        picks = []\n",
    "        total_len = 0\n",
    "        for i in order:\n",
    "            if total_len + nfps[i] < limits:\n",
    "                picks.append(i)\n",
    "                total_len += nfps[i]\n",
    "    else:\n",
    "        raise KeyError(\"Unknown method {}\".format(method))\n",
    "\n",
    "    summary = np.zeros(n_frames, dtype=np.float32)\n",
    "    for seg_idx in picks:\n",
    "        first, last = cps[seg_idx]\n",
    "        summary[first:last + 1] = 1\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bbe7ee84-74ac-4d8a-88cd-df265110d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "def generate_gt_probs(cps, nfps, n_frames, gt_score):\n",
    "    n_segs = cps.shape[0]\n",
    "    seg_score = []\n",
    "    for seg_idx in range(n_segs):\n",
    "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
    "        # print(start,end)\n",
    "        scores = gt_score[start:end]\n",
    "        seg_score.append(float(scores.mean()))\n",
    "    \n",
    "    \n",
    "    shot_probs = softmax(torch.Tensor(seg_score))\n",
    "    gt_probs = np.zeros(n_frames, dtype=np.float32)\n",
    "    for seg_idx in range(n_segs):\n",
    "        first, last = cps[seg_idx]\n",
    "        gt_probs[first:last + 1] = shot_probs[seg_idx]\n",
    "    \n",
    "    return gt_probs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc28a06-f828-4abc-8ba9-14b5954ee620",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### )) TVSum User Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "669d2a5b-27ae-4bdf-9001-abe34768398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "    'annotation':tvsum_data+'/matlab/ydata-tvsum50.mat',\n",
    "    'dataset_h5':'extracted_features/normal/TVSum.h5',\n",
    "    'video_info':tvsum_data+'/data/ydata-tvsum50-info.tsv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a69057fb-a49f-47b5-9859-6f1b25a4a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tvsum(args):\n",
    "    info_df = pd.read_csv(args['video_info'], sep='\\t')\n",
    "    with h5py.File(args['annotation'], 'r') as mat, h5py.File(args['dataset_h5'], 'r+') as d:\n",
    "        for i in range(0,50):\n",
    "            uscore_idx = mat['tvsum50/user_anno'][i, 0]\n",
    "            user_scores = mat[uscore_idx]\n",
    "\n",
    "            gtscore_idx = mat['tvsum50/gt_score'][i, 0]\n",
    "            gt_score = np.squeeze(mat[gtscore_idx])\n",
    "            # gt_score = gt_score[::EXTRACT_FREQUENCY]\n",
    "\n",
    "            name_idx = mat['tvsum50/video'][i, 0]\n",
    "            video_title = \"\".join(chr(i[0]) for i in mat[name_idx][()])\n",
    "            video_name = 'video_'+str(i+1)\n",
    "\n",
    "#             if d[video_name+'/picks'][()].shape[0]<gt_score.shape[0]:\n",
    "#                 gt_score=gt_score[:d[video_name+'/picks'][()].shape[0]]\n",
    "#             if d[video_name+'/picks'][()].shape[0]>gt_score.shape[0]:\n",
    "#                 np.pad(gt_score,(0,d[video_name+'/picks'][()].shape[0]-gt_score.shape[0]),'constant')\n",
    "\n",
    "            print(i,video_name, video_title, user_scores.shape, d[video_name+'/picks'][()].shape)\n",
    "            \n",
    "            user_summary = []\n",
    "            cps = d[video_name + '/change_points'][()]\n",
    "            nfps = d[video_name + '/n_frame_per_seg'][()].tolist()\n",
    "            n_frames = d[video_name + '/n_frames'][()]\n",
    "            \n",
    "            gt_probs = generate_gt_probs(cps, nfps, n_frames, gt_score)\n",
    "            \n",
    "            for us in user_scores:\n",
    "                one_sum = make_user_summary(us, cps, n_frames, nfps)\n",
    "                user_summary.append(one_sum)\n",
    "                \n",
    "            print('GT frame level Probs:', len(gt_probs))\n",
    "            d.create_dataset(video_name + '/gt_score', data=gt_score)\n",
    "            d.create_dataset(video_name + '/gt_probs', data=gt_probs)\n",
    "            d.create_dataset(video_name + '/user_summary', data=user_summary)\n",
    "\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d7992b5a-6fef-4719-8746-2569aee912c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 video_1 AwmHb44_ouw (20, 10597) (706,)\n",
      "GT frame level Probs: 10597\n",
      "1 video_2 98MoyGZKHXc (20, 4688) (312,)\n",
      "GT frame level Probs: 4688\n",
      "2 video_3 J0nA4VgnoCo (20, 14019) (934,)\n",
      "GT frame level Probs: 14019\n",
      "3 video_4 gzDbaEs1Rlg (20, 7210) (480,)\n",
      "GT frame level Probs: 7210\n",
      "4 video_5 XzYM3PfTM4w (20, 3327) (221,)\n",
      "GT frame level Probs: 3327\n",
      "5 video_6 HT5vyqe0Xaw (20, 9671) (644,)\n",
      "GT frame level Probs: 9671\n",
      "6 video_7 sTEELN-vY30 (20, 4468) (297,)\n",
      "GT frame level Probs: 4468\n",
      "7 video_8 vdmoEJ5YbrQ (20, 9870) (658,)\n",
      "GT frame level Probs: 9870\n",
      "8 video_9 xwqBXPGE9pQ (20, 7010) (467,)\n",
      "GT frame level Probs: 7010\n",
      "9 video_10 akI8YFjEmUw (20, 3995) (266,)\n",
      "GT frame level Probs: 3995\n",
      "10 video_11 i3wAGJaaktw (20, 4700) (313,)\n",
      "GT frame level Probs: 4700\n",
      "11 video_12 Bhxk-O1Y7Ho (20, 13511) (900,)\n",
      "GT frame level Probs: 13511\n",
      "12 video_13 0tmA_C6XwfM (20, 3532) (235,)\n",
      "GT frame level Probs: 3532\n",
      "13 video_14 3eYKfiOEJNs (20, 4853) (323,)\n",
      "GT frame level Probs: 4853\n",
      "14 video_15 xxdtq8mxegs (20, 4324) (288,)\n",
      "GT frame level Probs: 4324\n",
      "15 video_16 WG0MBPpPC6I (20, 9534) (635,)\n",
      "GT frame level Probs: 9535\n",
      "16 video_17 Hl-__g2gn_A (20, 5846) (389,)\n",
      "GT frame level Probs: 5846\n",
      "17 video_18 Yi4Ij2NM7U4 (20, 9731) (648,)\n",
      "GT frame level Probs: 9731\n",
      "18 video_19 37rzWOQsNIw (20, 5742) (382,)\n",
      "GT frame level Probs: 5742\n",
      "19 video_20 LRw_obCPUt0 (20, 6241) (416,)\n",
      "GT frame level Probs: 6241\n",
      "20 video_21 cjibtmSLxQ4 (20, 19406) (1293,)\n",
      "GT frame level Probs: 19406\n",
      "21 video_22 b626MiF1ew4 (20, 5661) (377,)\n",
      "GT frame level Probs: 5661\n",
      "22 video_23 XkqCExn6_Us (20, 5631) (375,)\n",
      "GT frame level Probs: 5631\n",
      "23 video_24 GsAD1KT1xo8 (20, 4356) (290,)\n",
      "GT frame level Probs: 4356\n",
      "24 video_25 PJrm840pAUI (20, 6580) (438,)\n",
      "GT frame level Probs: 6580\n",
      "25 video_26 91IHQYk1IQM (20, 3312) (220,)\n",
      "GT frame level Probs: 3312\n",
      "26 video_27 RBCABdttQmI (20, 10917) (727,)\n",
      "GT frame level Probs: 10917\n",
      "27 video_28 z_6gVvQb2d0 (20, 8281) (552,)\n",
      "GT frame level Probs: 8281\n",
      "28 video_29 fWutDQy1nnY (20, 17527) (1168,)\n",
      "GT frame level Probs: 17527\n",
      "29 video_30 4wU_LUjG5Ic (20, 4005) (267,)\n",
      "GT frame level Probs: 4005\n",
      "30 video_31 VuWGsYPqAX8 (20, 5412) (360,)\n",
      "GT frame level Probs: 5412\n",
      "31 video_32 JKpqYvAdIsw (20, 3802) (253,)\n",
      "GT frame level Probs: 3802\n",
      "32 video_33 xmEERLqJ2kU (20, 13365) (891,)\n",
      "GT frame level Probs: 13365\n",
      "33 video_34 byxOvuiIJV0 (20, 3705) (247,)\n",
      "GT frame level Probs: 3705\n",
      "34 video_35 _xMr-HKMfVA (20, 4463) (297,)\n",
      "GT frame level Probs: 4463\n",
      "35 video_36 WxtbjNsCQ8A (20, 7959) (530,)\n",
      "GT frame level Probs: 7959\n",
      "36 video_37 uGu_10sucQo (20, 4009) (267,)\n",
      "GT frame level Probs: 4009\n",
      "37 video_38 EE-bNr36nyA (20, 2941) (196,)\n",
      "GT frame level Probs: 2941\n",
      "38 video_39 Se3oxnaPsz0 (20, 4165) (277,)\n",
      "GT frame level Probs: 4166\n",
      "39 video_40 oDXZc0tZe04 (20, 11414) (760,)\n",
      "GT frame level Probs: 11414\n",
      "40 video_41 qqR6AEXwxoQ (20, 8073) (538,)\n",
      "GT frame level Probs: 8073\n",
      "41 video_42 EYqVtI9YWJA (20, 5939) (395,)\n",
      "GT frame level Probs: 5939\n",
      "42 video_43 eQu1rNs0an0 (20, 4931) (328,)\n",
      "GT frame level Probs: 4931\n",
      "43 video_44 JgHubY5Vw3Y (20, 4304) (286,)\n",
      "GT frame level Probs: 4304\n",
      "44 video_45 iVt07TCkFM0 (20, 2500) (166,)\n",
      "GT frame level Probs: 2500\n",
      "45 video_46 E11zDS9XGzg (20, 15307) (1020,)\n",
      "GT frame level Probs: 15307\n",
      "46 video_47 NyBmCxDoHJU (20, 4740) (316,)\n",
      "GT frame level Probs: 4740\n",
      "47 video_48 kLxoNp-UchI (20, 3896) (259,)\n",
      "GT frame level Probs: 3896\n",
      "48 video_49 jcoYJXDG9sw (20, 5971) (398,)\n",
      "GT frame level Probs: 5971\n",
      "49 video_50 -esJrBWj2d8 (20, 6912) (460,)\n",
      "GT frame level Probs: 6912\n"
     ]
    }
   ],
   "source": [
    "get_tvsum(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
