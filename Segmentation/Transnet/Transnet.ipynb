{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174a72d4-b312-4e88-806a-ed94f62e2945",
   "metadata": {},
   "source": [
    "## Transnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd768e2-462c-413b-a890-56a38a4c4898",
   "metadata": {},
   "source": [
    "**installations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c145a59-b22e-49b6-a5aa-9c21420d4d56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in c:\\users\\msc 2\\anaconda3\\lib\\site-packages (1.4)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\msc 2\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\msc 2\\anaconda3\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\msc 2\\anaconda3\\lib\\site-packages (from ffmpeg-python) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg\n",
    "!pip install ffmpeg-python pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e396a89-2712-4665-ac74-a8834fb318cc",
   "metadata": {},
   "source": [
    "**packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f67310f-fd3f-4ed8-a0bc-88b06cb8b792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import ffmpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a806fe2-d062-4b70-86f6-81ed660737d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### )) Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2273688-fa20-4e32-bca8-1501f7276d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path='../../data'\n",
    "public_dataset_path=datasets_path+'/Public datasets'\n",
    "custom_data = datasets_path+'/Custom data'\n",
    "\n",
    "tvsum_data = public_dataset_path+'/ydata-tvsum50-v1_1'\n",
    "summe_data = public_dataset_path+'/SUMMe'\n",
    "\n",
    "result_path= 'transnet_segments/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542910e-bbc0-401e-aa88-aee2a4a74c3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### )) Transnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3156161-9fa1-4488-b922-5c59ec31a77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransNetV2:\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        model_dir = \"transnetv2-weights/\"\n",
    "        self._input_size = (27, 48, 3)\n",
    "        try:\n",
    "            self._model = tf.saved_model.load(model_dir)\n",
    "        except OSError as exc:\n",
    "            raise IOError(f\"[TransNetV2] It seems that files in {model_dir} are corrupted or missing. \"\n",
    "                          f\"Re-download them manually and retry. For more info, see: \"\n",
    "                          f\"https://github.com/soCzech/TransNetV2/issues/1#issuecomment-647357796\") from exc\n",
    "\n",
    "    def predict_raw(self, frames: np.ndarray):\n",
    "        assert len(frames.shape) == 5 and frames.shape[2:] == self._input_size, \\\n",
    "            \"[TransNetV2] Input shape must be [batch, frames, height, width, 3].\"\n",
    "        frames = tf.cast(frames, tf.float32)\n",
    "        logits, dict_ = self._model(frames)\n",
    "        single_frame_pred = tf.sigmoid(logits)\n",
    "        # all_frames_pred = tf.sigmoid(dict_[\"many_hot\"])\n",
    "        \n",
    "        return single_frame_pred\n",
    "    # , all_frames_pred\n",
    "\n",
    "    def predict_frames(self, frames: np.ndarray):\n",
    "        assert len(frames.shape) == 4 and frames.shape[1:] == self._input_size, \"[TransNetV2] Input shape must be [frames, height, width, 3].\"\n",
    "\n",
    "        def input_iterator():\n",
    "            # return windows of size 100 where the first/last 25 frames are from the previous/next batch\n",
    "            # the first and last window must be padded by copies of the first and last frame of the video\n",
    "            no_padded_frames_start = 25\n",
    "            no_padded_frames_end = 25 + 50 - (len(frames) % 50 if len(frames) % 50 != 0 else 50)  # 25 - 74\n",
    "\n",
    "            start_frame = np.expand_dims(frames[0], 0)\n",
    "            end_frame = np.expand_dims(frames[-1], 0)\n",
    "            padded_inputs = np.concatenate(\n",
    "                [start_frame] * no_padded_frames_start + [frames] + [end_frame] * no_padded_frames_end, 0\n",
    "            )\n",
    "\n",
    "            ptr = 0\n",
    "            while ptr + 100 <= len(padded_inputs):\n",
    "                out = padded_inputs[ptr:ptr + 100]\n",
    "                ptr += 50\n",
    "                yield out[np.newaxis]\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for inp in input_iterator():\n",
    "            # single_frame_pred, all_frames_pred = self.predict_raw(inp)\n",
    "            single_frame_pred = self.predict_raw(inp)\n",
    "            predictions.append((single_frame_pred.numpy()[0, 25:75, 0]))\n",
    "\n",
    "            print(\"\\r[TransNetV2] Processing video frames {}/{}\".format(\n",
    "                min(len(predictions) * 50, len(frames)), len(frames)\n",
    "            ), end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "        single_frame_pred = np.concatenate([single_ for single_ in predictions])\n",
    "        # all_frames_pred = np.concatenate([all_ for single_, all_ in predictions])\n",
    "\n",
    "        # return single_frame_pred[:len(frames)], all_frames_pred[:len(frames)]  # remove extra padded frames\n",
    "        return single_frame_pred[:len(frames)]\n",
    "\n",
    "    def predict_video(self, video_fn: str):\n",
    "\n",
    "        print(\"[TransNetV2] Extracting frames from {}\".format(video_fn))\n",
    "        video_stream, err = ffmpeg.input(video_fn).output(\n",
    "            \"pipe:\", format=\"rawvideo\", pix_fmt=\"rgb24\", s=\"48x27\"\n",
    "        ).run(capture_stdout=True, capture_stderr=True)\n",
    "\n",
    "        video = np.frombuffer(video_stream, np.uint8).reshape([-1, 27, 48, 3])\n",
    "        return self.predict_frames(video)\n",
    "\n",
    "    @staticmethod\n",
    "    def predictions_to_scenes(predictions: np.ndarray, threshold: float = 0.5):\n",
    "        predictions = (predictions > threshold).astype(np.uint8)\n",
    "\n",
    "        scenes = []\n",
    "        t, t_prev, start = -1, 0, 0\n",
    "        for i, t in enumerate(predictions):\n",
    "            if t_prev == 1 and t == 0:\n",
    "                start = i\n",
    "            if t_prev == 0 and t == 1 and i != 0:\n",
    "                scenes.append([start, i])\n",
    "            t_prev = t\n",
    "        if t == 0:\n",
    "            scenes.append([start, i])\n",
    "\n",
    "        # just fix if all predictions are 1\n",
    "        if len(scenes) == 0:\n",
    "            return np.array([[0, len(predictions) - 1]], dtype=np.int32)\n",
    "\n",
    "        return np.array(scenes, dtype=np.int32)\n",
    "\n",
    "\n",
    "def main(args, mappings=None):\n",
    "    model = TransNetV2()\n",
    "    video_folder = args['videoFolder_path']+'/video/'\n",
    "    files = os.listdir(video_folder)\n",
    "    c=0\n",
    "    \n",
    "    \n",
    "    with h5py.File(args['cpsH5_path'],'a') as d:\n",
    "        for file in files:\n",
    "            if mappings!=None:\n",
    "                 name = 'video_'+str(mappings.index(file.split('.')[0])+1)\n",
    "            else:\n",
    "                name = 'video_'+str(c)\n",
    "                \n",
    "            if name in d:\n",
    "                c+=1\n",
    "                continue\n",
    "                \n",
    "            # video_frames, \n",
    "            single_frame_predictions= model.predict_video(video_folder+file)\n",
    "            scenes = model.predictions_to_scenes(single_frame_predictions)\n",
    "\n",
    "            c=c+1\n",
    "            print(str(c)+'. '+file+' as '+name+'; no.of shots='+str(len(scenes)))\n",
    "            d.create_dataset(name+'/change_points', data=scenes )\n",
    "            d.create_dataset(name+'/video_name', data=file )\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcf448-9af7-4782-83d8-a2e403e15af6",
   "metadata": {},
   "source": [
    "#### )) TVSum segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d106f99b-72b5-40bb-97b5-8749ef56299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arguments\n",
    "args={\n",
    "    'videoFolder_path': tvsum_data,\n",
    "    'cpsH5_path': result_path+'/tvsumSegs.h5',    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60f5ac4-8955-449e-a96e-4d723e762266",
   "metadata": {},
   "outputs": [],
   "source": [
    "## video name mappings\n",
    "tvsum_info=pd.read_csv(tvsum_data+'/data/ydata-tvsum50-info.tsv',sep='\\t')\n",
    "vnames = tvsum_info['video_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522b299c-2a8f-4516-9c9d-bf85bd45b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/Bhxk-O1Y7Ho.mp4\n",
      "[TransNetV2] Processing video frames 13511/13511\n",
      "11. Bhxk-O1Y7Ho.mp4 as video_12; no.of shots=43\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/byxOvuiIJV0.mp4\n",
      "[TransNetV2] Processing video frames 3705/3705\n",
      "12. byxOvuiIJV0.mp4 as video_34; no.of shots=53\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/cjibtmSLxQ4.mp4\n",
      "[TransNetV2] Processing video frames 19406/19406\n",
      "13. cjibtmSLxQ4.mp4 as video_21; no.of shots=157\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/E11zDS9XGzg.mp4\n",
      "[TransNetV2] Processing video frames 15307/15307\n",
      "14. E11zDS9XGzg.mp4 as video_46; no.of shots=13\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/EE-bNr36nyA.mp4\n",
      "[TransNetV2] Processing video frames 2941/2941\n",
      "15. EE-bNr36nyA.mp4 as video_38; no.of shots=17\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/eQu1rNs0an0.mp4\n",
      "[TransNetV2] Processing video frames 4931/4931\n",
      "16. eQu1rNs0an0.mp4 as video_43; no.of shots=30\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/EYqVtI9YWJA.mp4\n",
      "[TransNetV2] Processing video frames 5939/5939\n",
      "17. EYqVtI9YWJA.mp4 as video_42; no.of shots=23\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/fWutDQy1nnY.mp4\n",
      "[TransNetV2] Processing video frames 17527/17527\n",
      "18. fWutDQy1nnY.mp4 as video_29; no.of shots=31\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/GsAD1KT1xo8.mp4\n",
      "[TransNetV2] Processing video frames 4356/4356\n",
      "19. GsAD1KT1xo8.mp4 as video_24; no.of shots=39\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/gzDbaEs1Rlg.mp4\n",
      "[TransNetV2] Processing video frames 7210/7210\n",
      "20. gzDbaEs1Rlg.mp4 as video_4; no.of shots=60\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/Hl-__g2gn_A.mp4\n",
      "[TransNetV2] Processing video frames 5846/5846\n",
      "21. Hl-__g2gn_A.mp4 as video_17; no.of shots=34\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/HT5vyqe0Xaw.mp4\n",
      "[TransNetV2] Processing video frames 9671/9671\n",
      "22. HT5vyqe0Xaw.mp4 as video_6; no.of shots=25\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/i3wAGJaaktw.mp4\n",
      "[TransNetV2] Processing video frames 4700/4700\n",
      "23. i3wAGJaaktw.mp4 as video_11; no.of shots=15\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/iVt07TCkFM0.mp4\n",
      "[TransNetV2] Processing video frames 2500/2500\n",
      "24. iVt07TCkFM0.mp4 as video_45; no.of shots=29\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/J0nA4VgnoCo.mp4\n",
      "[TransNetV2] Processing video frames 14019/14019\n",
      "25. J0nA4VgnoCo.mp4 as video_3; no.of shots=23\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/jcoYJXDG9sw.mp4\n",
      "[TransNetV2] Processing video frames 5971/5971\n",
      "26. jcoYJXDG9sw.mp4 as video_49; no.of shots=30\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/JgHubY5Vw3Y.mp4\n",
      "[TransNetV2] Processing video frames 4304/4304\n",
      "27. JgHubY5Vw3Y.mp4 as video_44; no.of shots=26\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/JKpqYvAdIsw.mp4\n",
      "[TransNetV2] Processing video frames 3802/3802\n",
      "28. JKpqYvAdIsw.mp4 as video_32; no.of shots=55\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/kLxoNp-UchI.mp4\n",
      "[TransNetV2] Processing video frames 3896/3896\n",
      "29. kLxoNp-UchI.mp4 as video_48; no.of shots=25\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/LRw_obCPUt0.mp4\n",
      "[TransNetV2] Processing video frames 6241/6241\n",
      "30. LRw_obCPUt0.mp4 as video_20; no.of shots=36\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/NyBmCxDoHJU.mp4\n",
      "[TransNetV2] Processing video frames 4740/4740\n",
      "31. NyBmCxDoHJU.mp4 as video_47; no.of shots=36\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/oDXZc0tZe04.mp4\n",
      "[TransNetV2] Processing video frames 11414/11414\n",
      "32. oDXZc0tZe04.mp4 as video_40; no.of shots=2\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/PJrm840pAUI.mp4\n",
      "[TransNetV2] Processing video frames 6580/6580\n",
      "33. PJrm840pAUI.mp4 as video_25; no.of shots=59\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/qqR6AEXwxoQ.mp4\n",
      "[TransNetV2] Processing video frames 8073/8073\n",
      "34. qqR6AEXwxoQ.mp4 as video_41; no.of shots=16\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/RBCABdttQmI.mp4\n",
      "[TransNetV2] Processing video frames 10917/10917\n",
      "35. RBCABdttQmI.mp4 as video_27; no.of shots=85\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/Se3oxnaPsz0.mp4\n",
      "[TransNetV2] Processing video frames 4166/4166\n",
      "36. Se3oxnaPsz0.mp4 as video_39; no.of shots=27\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/sTEELN-vY30.mp4\n",
      "[TransNetV2] Processing video frames 4468/4468\n",
      "37. sTEELN-vY30.mp4 as video_7; no.of shots=26\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/uGu_10sucQo.mp4\n",
      "[TransNetV2] Processing video frames 4009/4009\n",
      "38. uGu_10sucQo.mp4 as video_37; no.of shots=33\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/vdmoEJ5YbrQ.mp4\n",
      "[TransNetV2] Processing video frames 9870/9870\n",
      "39. vdmoEJ5YbrQ.mp4 as video_8; no.of shots=2\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/VuWGsYPqAX8.mp4\n",
      "[TransNetV2] Processing video frames 5412/5412\n",
      "40. VuWGsYPqAX8.mp4 as video_31; no.of shots=101\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/WG0MBPpPC6I.mp4\n",
      "[TransNetV2] Processing video frames 9535/9535\n",
      "41. WG0MBPpPC6I.mp4 as video_16; no.of shots=60\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/WxtbjNsCQ8A.mp4\n",
      "[TransNetV2] Processing video frames 7959/7959\n",
      "42. WxtbjNsCQ8A.mp4 as video_36; no.of shots=27\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/XkqCExn6_Us.mp4\n",
      "[TransNetV2] Processing video frames 5631/5631\n",
      "43. XkqCExn6_Us.mp4 as video_23; no.of shots=40\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/xmEERLqJ2kU.mp4\n",
      "[TransNetV2] Processing video frames 13365/13365\n",
      "44. xmEERLqJ2kU.mp4 as video_33; no.of shots=1\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/xwqBXPGE9pQ.mp4\n",
      "[TransNetV2] Processing video frames 7010/7010\n",
      "45. xwqBXPGE9pQ.mp4 as video_9; no.of shots=33\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/xxdtq8mxegs.mp4\n",
      "[TransNetV2] Processing video frames 4324/4324\n",
      "46. xxdtq8mxegs.mp4 as video_15; no.of shots=11\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/XzYM3PfTM4w.mp4\n",
      "[TransNetV2] Processing video frames 3327/3327\n",
      "47. XzYM3PfTM4w.mp4 as video_5; no.of shots=19\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/Yi4Ij2NM7U4.mp4\n",
      "[TransNetV2] Processing video frames 9731/9731\n",
      "48. Yi4Ij2NM7U4.mp4 as video_18; no.of shots=36\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/z_6gVvQb2d0.mp4\n",
      "[TransNetV2] Processing video frames 8281/8281\n",
      "49. z_6gVvQb2d0.mp4 as video_28; no.of shots=1\n",
      "[TransNetV2] Extracting frames from ../../data/Public datasets/ydata-tvsum50-v1_1/video/_xMr-HKMfVA.mp4\n",
      "[TransNetV2] Processing video frames 4463/4463\n",
      "50. _xMr-HKMfVA.mp4 as video_35; no.of shots=52\n"
     ]
    }
   ],
   "source": [
    "## generate segments\n",
    "main(args, vnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
