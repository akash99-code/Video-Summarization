{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2223a-713c-417a-ad2a-f543c805068e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AONet:\n",
    "\n",
    "    def __init__(self, hps: HParameters):\n",
    "        self.hps = hps\n",
    "        self.model = None\n",
    "        self.log_file = None\n",
    "        self.verbose = hps.verbose\n",
    "\n",
    "\n",
    "    def initialize(self, cuda_device=None):\n",
    "        rnd_seed = 12345\n",
    "        random.seed(rnd_seed)\n",
    "        np.random.seed(rnd_seed)\n",
    "        torch.manual_seed(rnd_seed)\n",
    "\n",
    "        self.model = VASNet()\n",
    "        self.model.eval()\n",
    "        self.model.apply(weights_init)##?\n",
    "        #print(self.model)\n",
    "\n",
    "        cuda_device = cuda_device or self.hps.cuda_device\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            print(\"Setting CUDA device: \",cuda_device)\n",
    "            torch.cuda.set_device(cuda_device)\n",
    "            torch.cuda.manual_seed(rnd_seed)\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            self.model.cuda()\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def load_datasets(self, datasets = None):\n",
    "        \"\"\"\n",
    "        Loads all h5 datasets from the datasets list into a dictionary self.dataset\n",
    "        referenced by their base filename\n",
    "        :param datasets:  List of dataset filenames\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if datasets is None:\n",
    "            datasets = self.hps.datasets\n",
    "\n",
    "        datasets_dict = {}\n",
    "        for dataset in datasets:\n",
    "            _, base_filename = os.path.split(dataset)\n",
    "            base_filename, _ = os.path.splitext(base_filename)\n",
    "            print(\"Loading:\", dataset)\n",
    "            # dataset_name = base_filename.split('_')[2]\n",
    "            # print(\"\\tDataset name:\", dataset_name)\n",
    "            # datasets_dict[base_filename] = h5py.File(dataset, 'r')\n",
    "            datasets_dict[base_filename] = dataset\n",
    "\n",
    "        self.datasets_dict = datasets_dict\n",
    "        \n",
    "        return datasets_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def load_model(self, model_filename):\n",
    "        self.model.load_state_dict(torch.load(model_filename, map_location=lambda storage, loc: storage))\n",
    "        return\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def fix_keys(self, keys, dataset_name = None):\n",
    "#         \"\"\"\n",
    "#         :param keys:\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         # dataset_name = None\n",
    "#         if len(self.datasets) == 1:\n",
    "#             dataset_name = next(iter(self.datasets))\n",
    "\n",
    "#         keys_out = []\n",
    "#         for key in keys:\n",
    "#             t = key.split('/')\n",
    "#             if len(t) != 2:\n",
    "#                 assert dataset_name is not None, \"ERROR dataset name in some keys is missing but there are multiple dataset {} to choose from\".format(len(self.datasets))\n",
    "\n",
    "#                 key_name = dataset_name+'/'+key\n",
    "#                 keys_out.append(key_name)\n",
    "#             else:\n",
    "#                 keys_out.append(key)\n",
    "\n",
    "#         return keys_out\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def load_split_file(self, splits_file):\n",
    "\n",
    "        self.dataset_name, self.dataset_type, self.splits = parse_splits_filename(splits_file)\n",
    "        n_folds = len(self.splits)\n",
    "        self.split_file = splits_file\n",
    "        print(\"Loading splits from: \",splits_file)\n",
    "\n",
    "        return n_folds\n",
    "\n",
    "\n",
    "#     def select_split(self, split_id):\n",
    "#         print(\"Selecting split: \",split_id)\n",
    "\n",
    "#         self.split_id = split_id\n",
    "#         n_folds = len(self.splits)\n",
    "#         assert self.split_id < n_folds, \"split_id (got {}) exceeds {}\".format(self.split_id, n_folds)\n",
    "\n",
    "#         split = self.splits[self.split_id]\n",
    "#         self.train_keys = split['train_keys']\n",
    "#         self.test_keys = split['test_keys']\n",
    "\n",
    "#         dataset_filename = self.hps.get_dataset_by_name(self.dataset_name)[0]\n",
    "#         _,dataset_filename = os.path.split(dataset_filename)\n",
    "#         dataset_filename,_ = os.path.splitext(dataset_filename)\n",
    "#         self.train_keys = self.fix_keys(self.train_keys, dataset_filename)\n",
    "#         self.test_keys = self.fix_keys(self.test_keys, dataset_filename)\n",
    "#         return\n",
    "\n",
    "\n",
    "\n",
    "#     def get_data(self, key):\n",
    "#         key_parts = key.split('/')\n",
    "#         assert len(key_parts) == 2, \"ERROR. Wrong key name: \"+key\n",
    "#         dataset, key = key_parts\n",
    "#         return self.datasets[dataset][key]\n",
    "\n",
    "#     def lookup_weights_file(self, data_path):\n",
    "#         dataset_type_str = '' if self.dataset_type == '' else self.dataset_type + '_'\n",
    "#         weights_filename = data_path + '/models/{}_{}splits_{}_*.tar.pth'.format(self.dataset_name, dataset_type_str, self.split_id)\n",
    "#         weights_filename = glob.glob(weights_filename)\n",
    "#         if len(weights_filename) == 0:\n",
    "#             print(\"Couldn't find model weights: \", weights_filename)\n",
    "#             return ''\n",
    "\n",
    "#         # Get the first weights filename in the dir\n",
    "#         weights_filename = weights_filename[0]\n",
    "#         splits_file = data_path + '/splits/{}_{}splits.json'.format(self.dataset_name, dataset_type_str)\n",
    "\n",
    "#         return weights_filename, splits_file\n",
    "\n",
    "\n",
    "    def train(self, output_dir='EX-0'):\n",
    "\n",
    "        print(\"Initializing VASNet model and optimizer...\")\n",
    "        self.model.train()\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(parameters, lr=self.hps.lr[0], weight_decay=self.hps.l2_req)\n",
    "\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "        max_val_fscore = 0\n",
    "        max_val_fscore_epoch = 0\n",
    "        train_keys = self.train_keys[:]\n",
    "\n",
    "        lr = self.hps.lr[0]\n",
    "        for epoch in range(self.hps.epochs_max):\n",
    "\n",
    "            print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(self.hps.epochs_max)), end='')\n",
    "            self.model.train()\n",
    "            avg_loss = []\n",
    "\n",
    "            random.shuffle(train_keys)\n",
    "\n",
    "            for i, key in enumerate(train_keys):\n",
    "                dataset = self.get_data(key)\n",
    "                seq = dataset['features'][...]\n",
    "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "                target = dataset['gt_score'][...]\n",
    "                target = torch.from_numpy(target).unsqueeze(0)\n",
    "\n",
    "                # Normalize frame scores\n",
    "                target -= target.min()\n",
    "                target /= target.max()\n",
    "\n",
    "                if self.hps.use_cuda:\n",
    "                    seq, target = seq.float().cuda(), target.float().cuda()\n",
    "\n",
    "                seq_len = seq.shape[1]\n",
    "                y, _ = self.model(seq,seq_len)\n",
    "                loss_att = 0\n",
    "\n",
    "                loss = criterion(y, target)\n",
    "                # loss2 = y.sum()/seq_len\n",
    "                loss = loss + loss_att\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                avg_loss.append([float(loss), float(loss_att)])\n",
    "\n",
    "            # Evaluate test dataset\n",
    "            val_fscore, video_scores = self.eval(self.test_keys)\n",
    "            if max_val_fscore < val_fscore:\n",
    "                max_val_fscore = val_fscore\n",
    "                max_val_fscore_epoch = epoch\n",
    "\n",
    "            avg_loss = np.array(avg_loss)\n",
    "            print(\"   Train loss: {0:.05f}\".format(np.mean(avg_loss[:, 0])), end='')\n",
    "            print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore))\n",
    "\n",
    "            if self.verbose:\n",
    "                video_scores = [[\"No\", \"Video\", \"F-score\"]] + video_scores\n",
    "                print_table(video_scores, cell_width=[3,40,8])\n",
    "\n",
    "            # Save model weights\n",
    "            path, filename = os.path.split(self.split_file)\n",
    "            base_filename, _ = os.path.splitext(filename)\n",
    "            path = os.path.join(output_dir, 'models_temp', base_filename+'_'+str(self.split_id))\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            filename = str(epoch)+'_'+str(round(val_fscore*100,3))+'.pth.tar'\n",
    "            torch.save(self.model.state_dict(), os.path.join(path, filename))\n",
    "\n",
    "        return max_val_fscore, max_val_fscore_epoch\n",
    "\n",
    "\n",
    "#     def eval(self, dataset, keys=None, results_filename=None):\n",
    "\n",
    "#         self.model.eval()\n",
    "#         summary = {}\n",
    "#         att_vecs = {}\n",
    "        \n",
    "#         with torch.no_grad(), h5py.File(self.datasets_dict[dataset], 'a') as d:\n",
    "#             if keys==None:\n",
    "#                 keys=d.keys()\n",
    "                \n",
    "#             for i, key in enumerate(keys):\n",
    "#                 # data = self.get_data(key)\n",
    "#                 # seq = self.dataset[key]['features'][...]\n",
    "#                 seq = d[key]['features'][...]\n",
    "#                 seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "\n",
    "#                 if self.hps.use_cuda:\n",
    "#                     seq = seq.float().cuda()\n",
    "\n",
    "#                 y, att_vec = self.model(seq, seq.shape[1])\n",
    "#                 summary[key] = y[0].detach().cpu().numpy()\n",
    "#                 att_vecs[key] = att_vec.detach().cpu().numpy()\n",
    "\n",
    "#             f_score, video_scores = self.eval_summary(summary, keys,  d, results_filename=results_filename, metric=self.hps.dataset_name, att_vecs=att_vecs)\n",
    "\n",
    "#         return f_score, video_scores\n",
    "\n",
    "\n",
    "#     def eval_summary(self, machine_summary_activations, test_keys, dataset,  results_filename=None, metric='tvsum', att_vecs=None):\n",
    "\n",
    "#         eval_metric = 'avg' if metric == 'tvsum' else 'max'\n",
    "\n",
    "#         if results_filename is None:\n",
    "#             results_filename = 'results/test_result001.h5'\n",
    "#         fms = []\n",
    "#         video_scores = []\n",
    "\n",
    "#         with h5py.File(results_filename, 'w') as h5_res:\n",
    "        \n",
    "#             for key_idx, key in enumerate(test_keys):\n",
    "#                 d = dataset[key]\n",
    "#                 probs = machine_summary_activations[key]\n",
    "\n",
    "#                 if 'change_points' not in d:\n",
    "#                     print(\"ERROR: No change points in dataset/video \",key)\n",
    "\n",
    "#                 cps = d['change_points'][...]\n",
    "#                 num_frames = d['n_frames'][()]\n",
    "#                 nfps = d['n_frame_per_seg'][...].tolist()\n",
    "#                 positions = d['picks'][...]\n",
    "#                 # user_summary = d['user_summary'][...]\n",
    "\n",
    "#                 machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "#                 # fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
    "#                 # fms.append(fm)\n",
    "\n",
    "#                 # Reporting & logging\n",
    "#                 video_scores.append([key_idx + 1, key, \"{:.1%}\".format(fm)])\n",
    "\n",
    "#                 if results_filename:\n",
    "#                     gt = d['gtscore'][...]\n",
    "#                     h5_res.create_dataset(key + '/score', data=probs)\n",
    "#                     h5_res.create_dataset(key + '/machine_summary', data=machine_summary)\n",
    "#                     h5_res.create_dataset(key + '/gtscore', data=gt)\n",
    "#                     # h5_res.create_dataset(key + '/fm', data=fm)\n",
    "#                     h5_res.create_dataset(key + '/picks', data=positions)\n",
    "\n",
    "#                     video_name = key.split('/')[1]\n",
    "#                     if 'video_name' in d:\n",
    "#                         video_name = d['video_name'][...]\n",
    "#                     h5_res.create_dataset(key + '/video_name', data=video_name)\n",
    "\n",
    "#                     if att_vecs is not None:\n",
    "#                         h5_res.create_dataset(key + '/att', data=att_vecs[key])\n",
    "\n",
    "#         mean_fm = np.mean(fms)\n",
    "\n",
    "#         # Reporting & logging\n",
    "#         # if results_filename is not None:\n",
    "#         #     h5_res.close()\n",
    "\n",
    "#         return mean_fm, video_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09359075-0c6a-4b86-aeda-ecc687e5c2b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(hps):\n",
    "    # os.makedirs(hps.output_dir, exist_ok=True)\n",
    "    # os.makedirs(os.path.join(hps.output_dir, 'splits'), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(hps.output_dir, 'code'), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(hps.output_dir, 'models'), exist_ok=True)\n",
    "    # os.system('cp -f splits/*.json  ' + hps.output_dir + '/splits/')\n",
    "    # os.system('cp *.py ' + hps.output_dir + '/code/')\n",
    "\n",
    "    # Create a file to collect results from all splits\n",
    "    f = open(hps.results_path, 'wt')\n",
    "           \n",
    "        \n",
    "    # for split_filename in hps.split_file:\n",
    "    #     dataset_name, dataset_type, splits = parse_splits_filename(split_filename)\n",
    "\n",
    "        # For no augmentation use only a dataset corresponding to the split file\n",
    "#         datasets = None\n",
    "#         if dataset_type == '':\n",
    "#             datasets = hps.get_dataset_by_name(dataset_name)\n",
    "\n",
    "#         if datasets is None:\n",
    "#             datasets = hps.datasets\n",
    "\n",
    "    f_avg = 0\n",
    "    f = open(hps.split_file)\n",
    "    splits = json.load(f)\n",
    "    n_folds = len(splits)\n",
    "    for split_id in range(n_folds):\n",
    "        ao = AONet(hps)\n",
    "        ao.initialize()\n",
    "        ao.load_datasets(datasets=datasets)\n",
    "        ao.load_split_file(splits_file=split_filename)\n",
    "        ao.select_split(split_id=split_id)\n",
    "\n",
    "        fscore, fscore_epoch = ao.train(output_dir=hps.output_dir)\n",
    "        f_avg += fscore\n",
    "\n",
    "        # Log F-score for this split_id\n",
    "        f.write(split_filename + ', ' + str(split_id) + ', ' + str(fscore) + ', ' + str(fscore_epoch) + '\\n')\n",
    "        f.flush()\n",
    "\n",
    "        # Save model with the highest F score\n",
    "        _, log_file = os.path.split(split_filename)\n",
    "        log_dir, _ = os.path.splitext(log_file)\n",
    "        log_dir += '_' + str(split_id)\n",
    "        log_file = os.path.join(hps.output_dir, 'models', log_dir) + '_' + str(fscore) + '.tar.pth'\n",
    "\n",
    "        os.makedirs(os.path.join(hps.output_dir, 'models', ), exist_ok=True)\n",
    "        os.system('mv ' + hps.output_dir + '/models_temp/' + log_dir + '/' + str(fscore_epoch) + '_*.pth.tar ' + log_file)\n",
    "        os.system('rm -rf ' + hps.output_dir + '/models_temp/' + log_dir)\n",
    "\n",
    "        print(\"Split: {0:}   Best F-score: {1:0.5f}   Model: {2:}\".format(split_filename, fscore, log_file))\n",
    "\n",
    "    # Write average F-score for all splits to the results.txt file\n",
    "    f_avg /= n_folds\n",
    "    f.write(split_filename + ', ' + str('avg') + ', ' + str(f_avg) + '\\n')\n",
    "    f.flush()\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ee811-c01a-4c60-8478-2d1c8a997895",
   "metadata": {},
   "source": [
    "## Vasnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbee983-1aa9-4cd4-9ea5-9c15170c7177",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e69143-7582-4c9e-81de-c9fe7b44c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import json\n",
    "\n",
    "import import_ipynb\n",
    "from Model import VASNet\n",
    "\n",
    "from ortools.algorithms import pywrapknapsack_solver\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e3eb6-8ea5-4d5e-b8d1-47b4b00d9e55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Util modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932d395f-b166-4925-8297-7c44f438fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_if_missing(directory):\n",
    "    if not osp.exists(directory):\n",
    "        try:\n",
    "            os.makedirs(directory)\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "def write_json(obj, fpath):\n",
    "    mkdir_if_missing(osp.dirname(fpath))\n",
    "    with open(fpath, 'w') as f:\n",
    "        json.dump(obj, f, indent=4, separators=(',', ': '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b34d5f-84d5-4c92-ac7c-c0c22a76a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random(keys, num_videos, num_train):\n",
    "    \"\"\"Random split\"\"\"\n",
    "    train_keys, test_keys = [], []\n",
    "    rnd_idxs = np.random.choice(range(num_videos), size=num_train, replace=False)\n",
    "    for key_idx, key in enumerate(keys):\n",
    "        if key_idx in rnd_idxs:\n",
    "            train_keys.append(key)\n",
    "        else:\n",
    "            test_keys.append(key)\n",
    "\n",
    "    assert len(set(train_keys) & set(test_keys)) == 0, \"Error: train_keys and test_keys overlap\"\n",
    "\n",
    "    return train_keys, test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d203a6e8-05a9-426b-9d80-220141b9d33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_splits_filename(splits_filename):\n",
    "    # Parse split file and count number of k_folds\n",
    "    spath, sfname = os.path.split(splits_filename)\n",
    "    sfname, _ = os.path.splitext(sfname)\n",
    "    dataset_name = sfname.split('_')[0]  # Get dataset name e.g. tvsum\n",
    "    dataset_type = sfname.split('_')[1]  # augmentation type e.g. aug\n",
    "\n",
    "    # The keyword 'splits' is used as the filename fields terminator from historical reasons.\n",
    "    if dataset_type == 'splits':\n",
    "        # Split type is not present\n",
    "        dataset_type = ''\n",
    "\n",
    "    # Get number of discrete splits within each split json file\n",
    "    with open(splits_filename, 'r') as sf:\n",
    "        splits = json.load(sf)\n",
    "\n",
    "    return dataset_name, dataset_type, splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8086414-51b2-4d85-9061-b55a3a2488a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname == 'Linear':\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2.0))\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e6ab2d-7669-4beb-9a1d-30d74bfaf6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_ortools(values, weights, items, capacity ):\n",
    "    scale = 1000\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    values = (values * scale).astype(np.int32)\n",
    "    weights = (weights).astype(np.int32)\n",
    "    capacity = capacity\n",
    "    osolver = pywrapknapsack_solver.KnapsackSolver(pywrapknapsack_solver.KnapsackSolver.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER,'test')\n",
    "    osolver.Init(values.tolist(), [weights.tolist()], [capacity])\n",
    "    computed_value = osolver.Solve()\n",
    "    packed_items = [x for x in range(0, len(weights))\n",
    "                    if osolver.BestSolutionContains(x)]\n",
    "\n",
    "    return packed_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625eb2e6-0e31-484c-aa05-5cb0dc6fb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
    "    \"\"\"Generate keyshot-based video summary i.e. a binary vector.\n",
    "    Args:\n",
    "    ---------------------------------------------\n",
    "    - ypred: predicted importance scores.\n",
    "    - cps: change points, 2D matrix, each row contains a segment.\n",
    "    - n_frames: original number of frames.\n",
    "    - nfps: number of frames per segment.\n",
    "    - positions: positions of subsampled frames in the original video.\n",
    "    - proportion: length of video summary (compared to original video length).\n",
    "    - method: defines how shots are selected, ['knapsack', 'rank'].\n",
    "    \"\"\"\n",
    "    n_segs = cps.shape[0]\n",
    "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
    "    if positions.dtype != int:\n",
    "        positions = positions.astype(np.int32)\n",
    "    if positions[-1] != n_frames:\n",
    "        positions = np.concatenate([positions, [n_frames]])\n",
    "    for i in range(len(positions) - 1):\n",
    "        pos_left, pos_right = positions[i], positions[i+1]\n",
    "        if i == len(ypred):\n",
    "            frame_scores[pos_left:pos_right] = 0\n",
    "        else:\n",
    "            frame_scores[pos_left:pos_right] = ypred[i]\n",
    "\n",
    "    seg_score = []\n",
    "    for seg_idx in range(n_segs):\n",
    "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
    "        scores = frame_scores[start:end]\n",
    "        seg_score.append(float(scores.mean()))\n",
    "\n",
    "    limits = int(math.floor(n_frames * proportion))\n",
    "\n",
    "    if method == 'knapsack':\n",
    "        #picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
    "        picks = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
    "    elif method == 'rank':\n",
    "        order = np.argsort(seg_score)[::-1].tolist()\n",
    "        picks = []\n",
    "        total_len = 0\n",
    "        for i in order:\n",
    "            if total_len + nfps[i] < limits:\n",
    "                picks.append(i)\n",
    "                total_len += nfps[i]\n",
    "    else:\n",
    "        raise KeyError(\"Unknown method {}\".format(method))\n",
    "\n",
    "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
    "    for seg_idx in range(n_segs):\n",
    "        nf = nfps[seg_idx]\n",
    "        if seg_idx in picks:\n",
    "            tmp = np.ones((nf), dtype=np.float32)\n",
    "        else:\n",
    "            tmp = np.zeros((nf), dtype=np.float32)\n",
    "        summary = np.concatenate((summary, tmp))\n",
    "\n",
    "    summary = np.delete(summary, 0) # delete the first element\n",
    "    return summary\n",
    "\n",
    "\n",
    "def evaluate_summary(machine_summary, user_summary, eval_metric='avg'):\n",
    "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
    "    Args:\n",
    "    --------------------------------\n",
    "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
    "    eval_metric = {'avg', 'max'}\n",
    "    'avg' averages results of comparing multiple human summaries.\n",
    "    'max' takes the maximum (best) out of multiple comparisons.\n",
    "    \"\"\"\n",
    "    machine_summary = machine_summary.astype(np.float32)\n",
    "    user_summary = user_summary.astype(np.float32)\n",
    "    n_users,n_frames = user_summary.shape\n",
    "\n",
    "    # binarization\n",
    "    machine_summary[machine_summary > 0] = 1\n",
    "    user_summary[user_summary > 0] = 1\n",
    "\n",
    "    if len(machine_summary) > n_frames:\n",
    "        machine_summary = machine_summary[:n_frames]\n",
    "    elif len(machine_summary) < n_frames:\n",
    "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
    "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
    "\n",
    "    f_scores = []\n",
    "    prec_arr = []\n",
    "    rec_arr = []\n",
    "\n",
    "    for user_idx in range(n_users):\n",
    "        gt_summary = user_summary[user_idx,:]\n",
    "        overlap_duration = (machine_summary * gt_summary).sum()\n",
    "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
    "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
    "        if precision == 0 and recall == 0:\n",
    "            f_score = 0.\n",
    "        else:\n",
    "            f_score = (2 * precision * recall) / (precision + recall)\n",
    "        f_scores.append(f_score)\n",
    "        prec_arr.append(precision)\n",
    "        rec_arr.append(recall)\n",
    "\n",
    "    if eval_metric == 'avg':\n",
    "        final_f_score = np.mean(f_scores)\n",
    "        final_prec = np.mean(prec_arr)\n",
    "        final_rec = np.mean(rec_arr)\n",
    "    elif eval_metric == 'max':\n",
    "        final_f_score = np.max(f_scores)\n",
    "        max_idx = np.argmax(f_scores)\n",
    "        final_prec = prec_arr[max_idx]\n",
    "        final_rec = rec_arr[max_idx]\n",
    "    \n",
    "    return final_f_score, final_prec, final_rec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf147d9-45af-4a83-ae5e-79fef04e592a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298da162-c1d0-4231-af02-4520cc5ad1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HParameters:\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        \n",
    "        self.verbose = args['verbose']\n",
    "        self.use_cuda = args['use_cuda']\n",
    "        self.cuda_device = args['cuda_device']\n",
    "        self.max_summary_length = args['max_summary_length']\n",
    "\n",
    "        self.l2_req = 0.00001\n",
    "        self.lr_epochs = [0]\n",
    "        self.lr = [0.00005]\n",
    "        self.epochs_max = 300\n",
    "        self.train_batch_size = 1\n",
    "\n",
    "        self.dataset=args['dataset']\n",
    "        self.results_path = args['results_path']\n",
    "        self.num_splits = args['num_splits']\n",
    "        self.split_file = args['split_file']\n",
    "        self.train_percent = args['train_percent']\n",
    "        \n",
    "        if 'model_path' in args:\n",
    "            self.model_path = args['model_path']\n",
    "        else:\n",
    "            self.model_path = None\n",
    "        return\n",
    "\n",
    "\n",
    "    def create_split(self):\n",
    "        print(\"Loading dataset from {}\".format(self.dataset))\n",
    "        \n",
    "        with h5py.File(self.dataset, 'r') as dataset:\n",
    "            keys = dataset.keys()\n",
    "            num_videos = len(keys)\n",
    "            num_train = int(math.ceil(num_videos * self.train_percent))\n",
    "            num_test = num_videos - num_train\n",
    "\n",
    "            print(\"Split breakdown: # total videos {}. # train videos {}. # test videos {}\".format(num_videos, num_train, num_test))\n",
    "            splits = []\n",
    "\n",
    "            for split_idx in range(self.num_splits):\n",
    "                train_keys, test_keys = split_random(keys, num_videos, num_train)\n",
    "                splits.append({\n",
    "                    'train_keys': train_keys,\n",
    "                    'test_keys': test_keys,\n",
    "                    })\n",
    "\n",
    "            # saveto = osp.join(self.split_file)\n",
    "            write_json(splits, self.split_file)\n",
    "            print(\"Splits saved to {}\".format(self.split_file))\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        vars = [attr for attr in dir(self) if not callable(getattr(self,attr)) and not (attr.startswith(\"__\") or attr.startswith(\"_\"))]\n",
    "\n",
    "        info_str = ''\n",
    "        for i, var in enumerate(vars):\n",
    "            val = getattr(self, var)\n",
    "            if isinstance(val, Variable):\n",
    "                val = val.data.cpu().numpy().tolist()[0]\n",
    "            info_str += '['+str(i)+'] '+var+': '+str(val)+'\\n'\n",
    "\n",
    "        return info_str\n",
    "    \n",
    "    \n",
    "#     def load_from_args(self, args):\n",
    "#         for key in args:\n",
    "#             val = args[key]\n",
    "#             if val is not None:\n",
    "#                 if hasattr(self, key) and isinstance(getattr(self, key), list):\n",
    "#                     val = val.split()\n",
    "\n",
    "#                 setattr(self, key, val)\n",
    "\n",
    "#     def get_dataset_by_name(self, dataset_name):\n",
    "#         for d in self.datasets:\n",
    "#             if dataset_name in d:\n",
    "#                 return [d]\n",
    "#         return None\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ec2db-e6eb-408f-9442-1e861711badc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "301dbd28-1415-4409-bb4d-821d0a41f72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, hps: HParameters):\n",
    "        self.hps = hps\n",
    "        self.model = VASNet()\n",
    "        self.verbose = True\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.show_every = 1\n",
    "        \n",
    "\n",
    "        \n",
    "    def init_model(self):\n",
    "        if self.hps.model_path:\n",
    "            self.model.load_state_dict(torch.load(self.hps.model_path, map_location=lambda storage, loc: storage))\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            self.model.apply(weights_init)\n",
    "        \n",
    "        \n",
    "    def train(self, train_keys):\n",
    "        losses=[]\n",
    "        for i, key in enumerate(train_keys):\n",
    "            with h5py.File(self.hps.dataset) as d:\n",
    "                seq= d[key]['features'][...]\n",
    "                target = d[key]['gt_score'][...]\n",
    "                target = target.astype(float)\n",
    "                \n",
    "            # seq = dataset['features'][...]\n",
    "            seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "            # target = dataset['gtscore'][...]\n",
    "            target = torch.from_numpy(target).unsqueeze(0)\n",
    "\n",
    "            # Min-Max Normalize frame scores\n",
    "            target -= target.min()\n",
    "            target /= target.max()\n",
    "            \n",
    "\n",
    "            if self.hps.use_cuda:\n",
    "                seq, target = seq.float().cuda(), target.float().cuda()\n",
    "\n",
    "            seq_len = seq.shape[1]\n",
    "            y, _ = self.model(seq,seq_len)\n",
    "            # print(y)\n",
    "            loss_att = 0\n",
    "\n",
    "            loss = self.criterion(y, target.float())\n",
    "            loss = loss + loss_att\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(float(loss))\n",
    "            \n",
    "        return np.mean(np.array(losses))\n",
    "\n",
    "    def video_fscore(self, machine_summary_activations, test_keys, metric='tvsum', att_vecs=None):\n",
    "        eval_metric = 'avg' if metric == 'tvsum' else 'max'\n",
    "\n",
    "        # if results_filename is not None:\n",
    "        #     h5_res = h5py.File(results_filename, 'w')\n",
    "\n",
    "        fms = []\n",
    "        video_scores = []\n",
    "        for key_idx, key in enumerate(test_keys):\n",
    "            \n",
    "            probs = machine_summary_activations[key]\n",
    "\n",
    "\n",
    "            with h5py.File(self.hps.dataset,'r') as d:\n",
    "                cps = d[key]['change_points'][...]\n",
    "                num_frames = d[key]['n_frames'][()]\n",
    "                nfps = d[key]['n_frame_per_seg'][...].tolist()\n",
    "                positions = d[key]['picks'][...]\n",
    "                user_summary = d[key]['user_summary'][...]\n",
    "\n",
    "            machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "            fm, _, _ = evaluate_summary(machine_summary, user_summary, eval_metric)\n",
    "            fms.append(fm)\n",
    "\n",
    "            # Reporting & logging\n",
    "            video_scores.append([key_idx + 1, key, \"{:.1%}\".format(fm)])\n",
    "            \n",
    "        mean_fm = np.mean(fms)\n",
    "        \n",
    "        return mean_fm, video_scores\n",
    "\n",
    "    def validate(self, test_keys):\n",
    "        self.model.eval()\n",
    "        summary = {}\n",
    "        att_vecs = {}\n",
    "        with torch.no_grad():\n",
    "            for i, key in enumerate(test_keys):\n",
    "                with h5py.File(self.hps.dataset) as d:\n",
    "                    seq = d[key]['features'][...]\n",
    "                    \n",
    "                seq = torch.from_numpy(seq).unsqueeze(0)\n",
    "\n",
    "                if self.hps.use_cuda:\n",
    "                    seq = seq.float().cuda()\n",
    "\n",
    "                y, att_vec = self.model(seq, seq.shape[1])\n",
    "                summary[key] = y[0].detach().cpu().numpy()\n",
    "                att_vecs[key] = att_vec.detach().cpu().numpy()\n",
    "\n",
    "        f_score, video_scores = self.video_fscore(summary, test_keys, att_vecs=att_vecs)\n",
    "        return f_score, video_scores\n",
    "        \n",
    "    def run(self):\n",
    "        print(\"Initializing VASNet model and optimizer...\")\n",
    "        self.init_model()\n",
    "        self.model.train()\n",
    "\n",
    "        if self.hps.use_cuda:\n",
    "            self.criterion = self.criterion.cuda()\n",
    "\n",
    "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        self.optimizer = torch.optim.Adam(parameters, lr=self.hps.lr[0], weight_decay=self.hps.l2_req)\n",
    "        \n",
    "        lr = self.hps.lr[0]\n",
    "        \n",
    "        f = open(hps.split_file)\n",
    "        splits = json.load(f)\n",
    "        n_folds = len(splits)\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        for split in splits:\n",
    "            max_val_fscore = 0\n",
    "            max_val_fscore_epoch = 0\n",
    "            train_keys = split['train_keys']\n",
    "            test_keys = split['test_keys']\n",
    "\n",
    "            epoch_losses=[]\n",
    "            for epoch in range(self.hps.epochs_max):\n",
    "\n",
    "                print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(self.hps.epochs_max)), end='')\n",
    "                self.model.train()\n",
    "\n",
    "                random.shuffle(train_keys)   \n",
    "                loss = self.train(train_keys)\n",
    "                epoch_losses.append(loss)\n",
    "                \n",
    "                \n",
    "                # Evaluate test dataset\n",
    "                val_fscore, video_scores = self.validate(test_keys)\n",
    "                if max_val_fscore < val_fscore:\n",
    "                    max_val_fscore = val_fscore\n",
    "                    max_val_fscore_epoch = epoch\n",
    "                \n",
    "                if epoch%self.show_every==0:\n",
    "                    print(f'Epoch:{epoch}, Loss:{loss}')\n",
    "\n",
    "            # avg_loss = np.array(epoch_losses)\n",
    "            print(\"   Train loss: {0:.05f}\".format(np.mean(np.array(epoch_losses))), end='')\n",
    "            # print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore))\n",
    "\n",
    "            if self.verbose:\n",
    "                video_scores = [[\"No\", \"Video\", \"F-score\"]] + video_scores\n",
    "                print_table(video_scores, cell_width=[3,40,8])\n",
    "\n",
    "        return max_val_fscore, max_val_fscore_epoch\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        # Save model weights\n",
    "        filename = name+'_'+str(epoch)+'_'+splitn+'.pth.tar'\n",
    "        torch.save(self.model.state_dict(), os.path.join('models', filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933537a9-9009-4d10-b65b-3d5b8a5f2af1",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee8605c-fa7c-4196-9abd-aadf592dfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "    'results_path':'training_results.txt',\n",
    "    'num_splits':5,\n",
    "    'split_file':'splits/test_split1.json',\n",
    "    'dataset': '../../Preprocessing/extracted_features/normal/TVSum.h5',\n",
    "    'train_percent':0.8,\n",
    "    'verbose':True,\n",
    "    'use_cuda' : False,\n",
    "    'cuda_device': None,\n",
    "    'max_summary_length': 0.15\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ae8df64-01ae-4755-a6e2-39f814bb4035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ../../Preprocessing/extracted_features/normal/TVSum.h5\n",
      "Split breakdown: # total videos 50. # train videos 40. # test videos 10\n",
      "Splits saved to splits/test_split1.json\n"
     ]
    }
   ],
   "source": [
    "hps = HParameters(args)\n",
    "# hps.load_from_args(args.__dict__)\n",
    "hps.create_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb419763-e8a9-4929-b0fa-676846e31fcb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing VASNet model and optimizer...\n",
      "Starting training...\n",
      "Epoch: 0/300 Epoch:0, Loss:0.2202379021793604\n",
      "Epoch: 1/300 Epoch:1, Loss:0.20131014492362737\n",
      "Epoch: 2/300 Epoch:2, Loss:0.1933257630094886\n",
      "Epoch: 3/300 Epoch:3, Loss:0.17167237289249898\n",
      "Epoch: 4/300 Epoch:4, Loss:0.16181218046694995\n",
      "Epoch: 5/300 Epoch:5, Loss:0.1554220153018832\n",
      "Epoch: 6/300 Epoch:6, Loss:0.14790790136903526\n",
      "Epoch: 7/300 Epoch:7, Loss:0.14590134508907796\n",
      "Epoch: 8/300 Epoch:8, Loss:0.13863646406680347\n",
      "Epoch: 9/300 Epoch:9, Loss:0.1390377800911665\n",
      "Epoch: 10/300Epoch:10, Loss:0.13635272160172462\n",
      "Epoch: 11/300Epoch:11, Loss:0.13643947867676615\n",
      "Epoch: 12/300Epoch:12, Loss:0.13478460973128675\n",
      "Epoch: 13/300Epoch:13, Loss:0.13450990822166203\n",
      "Epoch: 14/300Epoch:14, Loss:0.13215046357363464\n",
      "Epoch: 15/300Epoch:15, Loss:0.13190546222031116\n",
      "Epoch: 16/300Epoch:16, Loss:0.1320596646517515\n",
      "Epoch: 17/300Epoch:17, Loss:0.13363236943259835\n",
      "Epoch: 18/300Epoch:18, Loss:0.1306498414836824\n",
      "Epoch: 19/300Epoch:19, Loss:0.13337845746427773\n",
      "Epoch: 20/300Epoch:20, Loss:0.13052880307659506\n",
      "Epoch: 21/300Epoch:21, Loss:0.13055490171536804\n",
      "Epoch: 22/300Epoch:22, Loss:0.13087295414879918\n",
      "Epoch: 23/300Epoch:23, Loss:0.1296350528486073\n",
      "Epoch: 24/300Epoch:24, Loss:0.1298830730840564\n",
      "Epoch: 25/300Epoch:25, Loss:0.12976061319932342\n",
      "Epoch: 26/300Epoch:26, Loss:0.1304016575217247\n",
      "Epoch: 27/300Epoch:27, Loss:0.12998496564105153\n",
      "Epoch: 28/300Epoch:28, Loss:0.1301808931864798\n",
      "Epoch: 29/300Epoch:29, Loss:0.1293157609179616\n",
      "Epoch: 30/300Epoch:30, Loss:0.12993021700531243\n",
      "Epoch: 31/300Epoch:31, Loss:0.1305651175789535\n",
      "Epoch: 32/300Epoch:32, Loss:0.12980026379227638\n",
      "Epoch: 33/300Epoch:33, Loss:0.12950896443799137\n",
      "Epoch: 34/300Epoch:34, Loss:0.13014133591204882\n",
      "Epoch: 35/300Epoch:35, Loss:0.12853791201487183\n",
      "Epoch: 36/300Epoch:36, Loss:0.12869552159681916\n",
      "Epoch: 37/300Epoch:37, Loss:0.12893079863861204\n",
      "Epoch: 38/300Epoch:38, Loss:0.12810589149594306\n",
      "Epoch: 39/300Epoch:39, Loss:0.12885173903778196\n",
      "Epoch: 40/300Epoch:40, Loss:0.1276388649828732\n",
      "Epoch: 41/300Epoch:41, Loss:0.1275342194363475\n",
      "Epoch: 42/300Epoch:42, Loss:0.1285939222201705\n",
      "Epoch: 43/300Epoch:43, Loss:0.1281012339517474\n",
      "Epoch: 44/300Epoch:44, Loss:0.1265890747308731\n",
      "Epoch: 45/300Epoch:45, Loss:0.12766387574374677\n",
      "Epoch: 46/300Epoch:46, Loss:0.12689043618738652\n",
      "Epoch: 47/300Epoch:47, Loss:0.1264470516704023\n",
      "Epoch: 48/300Epoch:48, Loss:0.12596987839788198\n",
      "Epoch: 49/300Epoch:49, Loss:0.12685891836881638\n",
      "Epoch: 50/300Epoch:50, Loss:0.12518136948347092\n",
      "Epoch: 51/300Epoch:51, Loss:0.12619545292109252\n",
      "Epoch: 52/300Epoch:52, Loss:0.12438967693597078\n",
      "Epoch: 53/300Epoch:53, Loss:0.12472361782565713\n",
      "Epoch: 54/300Epoch:54, Loss:0.12606120286509395\n",
      "Epoch: 55/300Epoch:55, Loss:0.12429170133545994\n",
      "Epoch: 56/300Epoch:56, Loss:0.12347008613869548\n",
      "Epoch: 57/300Epoch:57, Loss:0.12297087460756302\n",
      "Epoch: 58/300Epoch:58, Loss:0.1239660314284265\n",
      "Epoch: 59/300Epoch:59, Loss:0.12421617256477475\n",
      "Epoch: 60/300Epoch:60, Loss:0.123158008325845\n",
      "Epoch: 61/300Epoch:61, Loss:0.1218802984803915\n",
      "Epoch: 62/300Epoch:62, Loss:0.12245423896238208\n",
      "Epoch: 63/300Epoch:63, Loss:0.12208845112472773\n",
      "Epoch: 64/300Epoch:64, Loss:0.12367373574525117\n",
      "Epoch: 65/300Epoch:65, Loss:0.12262465609237552\n",
      "Epoch: 66/300Epoch:66, Loss:0.1215210558846593\n",
      "Epoch: 67/300Epoch:67, Loss:0.12080519450828434\n",
      "Epoch: 68/300Epoch:68, Loss:0.12043687021359802\n",
      "Epoch: 69/300Epoch:69, Loss:0.11967523656785488\n",
      "Epoch: 70/300Epoch:70, Loss:0.11943171946331858\n",
      "Epoch: 71/300Epoch:71, Loss:0.1217811088077724\n",
      "Epoch: 72/300Epoch:72, Loss:0.12125352183356881\n",
      "Epoch: 73/300Epoch:73, Loss:0.12056074449792505\n",
      "Epoch: 74/300Epoch:74, Loss:0.11925120009109377\n",
      "Epoch: 75/300Epoch:75, Loss:0.11933346539735794\n",
      "Epoch: 76/300Epoch:76, Loss:0.11909491028636694\n",
      "Epoch: 77/300Epoch:77, Loss:0.11882491642609239\n",
      "Epoch: 78/300Epoch:78, Loss:0.11882553938776255\n",
      "Epoch: 79/300Epoch:79, Loss:0.11900141555815935\n",
      "Epoch: 80/300Epoch:80, Loss:0.11947991298511625\n",
      "Epoch: 81/300Epoch:81, Loss:0.12043925309553742\n",
      "Epoch: 82/300Epoch:82, Loss:0.11914610359817743\n",
      "Epoch: 83/300Epoch:83, Loss:0.11909736236557364\n",
      "Epoch: 84/300Epoch:84, Loss:0.11868425598368049\n",
      "Epoch: 85/300Epoch:85, Loss:0.11835888428613543\n",
      "Epoch: 86/300Epoch:86, Loss:0.11821469981223345\n",
      "Epoch: 87/300Epoch:87, Loss:0.11741441069170833\n",
      "Epoch: 88/300Epoch:88, Loss:0.11838089916855096\n",
      "Epoch: 89/300Epoch:89, Loss:0.11784182572737337\n",
      "Epoch: 90/300Epoch:90, Loss:0.11805676827207208\n",
      "Epoch: 91/300Epoch:91, Loss:0.11707172095775605\n",
      "Epoch: 92/300Epoch:92, Loss:0.11667315633967519\n",
      "Epoch: 93/300Epoch:93, Loss:0.11670939764007926\n",
      "Epoch: 94/300Epoch:94, Loss:0.11657835384830832\n",
      "Epoch: 95/300Epoch:95, Loss:0.11613230919465423\n",
      "Epoch: 96/300Epoch:96, Loss:0.11601897953078151\n",
      "Epoch: 97/300Epoch:97, Loss:0.11606920333579182\n",
      "Epoch: 98/300"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(hps)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    136\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(train_keys)   \n\u001b[1;32m--> 137\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Evaluate test dataset\u001b[39;00m\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, train_keys)\u001b[0m\n\u001b[0;32m     38\u001b[0m     seq, target \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcuda(), target\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     40\u001b[0m seq_len \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 41\u001b[0m y, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# print(y)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m loss_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m<string>:93\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, x, seq_len)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m<string>:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1834\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1834\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1835\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1836\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(hps)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e128302-6514-4aec-9fe2-22af48da162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0cc69-1791-4d60-8568-2d8c9711763b",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
