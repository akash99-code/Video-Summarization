{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1ee811-c01a-4c60-8478-2d1c8a997895",
   "metadata": {},
   "source": [
    "## Trirachical Tranining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbee983-1aa9-4cd4-9ea5-9c15170c7177",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e69143-7582-4c9e-81de-c9fe7b44c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import import_ipynb\n",
    "from Model import Trirar\n",
    "\n",
    "from ortools.algorithms import pywrapknapsack_solver\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e3eb6-8ea5-4d5e-b8d1-47b4b00d9e55",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Util modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932d395f-b166-4925-8297-7c44f438fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_if_missing(directory):\n",
    "    if not osp.exists(directory):\n",
    "        try:\n",
    "            os.makedirs(directory)\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "def write_json(obj, fpath):\n",
    "    mkdir_if_missing(osp.dirname(fpath))\n",
    "    with open(fpath, 'w') as f:\n",
    "        json.dump(obj, f, indent=4, separators=(',', ': '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b34d5f-84d5-4c92-ac7c-c0c22a76a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_random(keys, num_videos, num_train):\n",
    "    \"\"\"Random split\"\"\"\n",
    "    train_keys, test_keys = [], []\n",
    "    rnd_idxs = np.random.choice(range(num_videos), size=num_train, replace=False)\n",
    "    for key_idx, key in enumerate(keys):\n",
    "        if key_idx in rnd_idxs:\n",
    "            train_keys.append(key)\n",
    "        else:\n",
    "            test_keys.append(key)\n",
    "\n",
    "    assert len(set(train_keys) & set(test_keys)) == 0, \"Error: train_keys and test_keys overlap\"\n",
    "\n",
    "    return train_keys, test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1eaece-1d50-4a52-beb9-33f398d088ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(table, cell_width=[3,10,13,13]):\n",
    "    slen=sum(cell_width)+len(cell_width)*2+2\n",
    "    print('-'*slen)\n",
    "    header = table.pop(0)\n",
    "    for i, head in enumerate(header):\n",
    "        print('  {name: <{alignment}}'.format(name=head, alignment=cell_width[i]), end='')\n",
    "\n",
    "    print('')\n",
    "    print('='*slen)\n",
    "    for row in table:\n",
    "        for i, val in enumerate(row):\n",
    "            print('  {val: <{alignment}}'.format(val=val, alignment=cell_width[i]), end='')\n",
    "        print('')\n",
    "    print('-'*slen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d203a6e8-05a9-426b-9d80-220141b9d33c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_splits_filename(splits_filename):\n",
    "    # Parse split file and count number of k_folds\n",
    "    spath, sfname = os.path.split(splits_filename)\n",
    "    sfname, _ = os.path.splitext(sfname)\n",
    "    dataset_name = sfname.split('_')[0]  # Get dataset name e.g. tvsum\n",
    "    dataset_type = sfname.split('_')[1]  # augmentation type e.g. aug\n",
    "\n",
    "    # The keyword 'splits' is used as the filename fields terminator from historical reasons.\n",
    "    if dataset_type == 'splits':\n",
    "        # Split type is not present\n",
    "        dataset_type = ''\n",
    "\n",
    "    # Get number of discrete splits within each split json file\n",
    "    with open(splits_filename, 'r') as sf:\n",
    "        splits = json.load(sf)\n",
    "\n",
    "    return dataset_name, dataset_type, splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83232b22-7b6a-48d1-ad57-48fc76e5e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_probs(shot_probs, cps, n_frames, device):\n",
    "    if len(shot_probs) != len(cps):\n",
    "        print('no. of shots does not match:', len(shot_probs),len(cps))\n",
    "        return\n",
    "    frame_probs = torch.zeros(n_frames, dtype=torch.float32, device = device)\n",
    "    n_segs = cps.shape[0]\n",
    "    for seg_idx in range(n_segs):\n",
    "        first, last = cps[seg_idx]\n",
    "        first, last =  int(first.item()), int(last.item())\n",
    "        frame_probs[first:last + 1] = shot_probs[seg_idx]\n",
    "        \n",
    "    return frame_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8086414-51b2-4d85-9061-b55a3a2488a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname == 'Linear':\n",
    "        init.xavier_uniform_(m.weight, gain=np.sqrt(2.0))\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e6ab2d-7669-4beb-9a1d-30d74bfaf6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsack_ortools(values, weights, items, capacity ):\n",
    "    scale = 1000\n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)\n",
    "    values = (values * scale).astype(np.int32)\n",
    "    weights = (weights).astype(np.int32)\n",
    "    capacity = capacity\n",
    "    osolver = pywrapknapsack_solver.KnapsackSolver(pywrapknapsack_solver.KnapsackSolver.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER,'test')\n",
    "    osolver.Init(values.tolist(), [weights.tolist()], [capacity])\n",
    "    computed_value = osolver.Solve()\n",
    "    packed_items = [x for x in range(0, len(weights))\n",
    "                    if osolver.BestSolutionContains(x)]\n",
    "\n",
    "    return packed_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625eb2e6-0e31-484c-aa05-5cb0dc6fb3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
    "    \"\"\"Generate keyshot-based video summary i.e. a binary vector.\n",
    "    Args:\n",
    "    ---------------------------------------------\n",
    "    - ypred: predicted importance scores.\n",
    "    - cps: change points, 2D matrix, each row contains a segment.\n",
    "    - n_frames: original number of frames.\n",
    "    - nfps: number of frames per segment.\n",
    "    - positions: positions of subsampled frames in the original video.\n",
    "    - proportion: length of video summary (compared to original video length).\n",
    "    - method: defines how shots are selected, ['knapsack', 'rank'].\n",
    "    \"\"\"\n",
    "    n_segs = cps.shape[0]\n",
    "    if n_segs!=len(ypred):\n",
    "        print('Error')\n",
    "        return\n",
    "    # frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
    "    # if positions.dtype != int:\n",
    "    #     positions = positions.astype(np.int32)\n",
    "    # if positions[-1] != n_frames:\n",
    "    # #     positions = np.concatenate([positions, [n_frames]])\n",
    "    # for i in range(len(positions) - 1):\n",
    "    #     pos_left, pos_right = positions[i], positions[i+1]\n",
    "    #     if i == len(ypred):\n",
    "    #         frame_scores[pos_left:pos_right] = 0\n",
    "    #     else:\n",
    "    #         frame_scores[pos_left:pos_right] = ypred[i]\n",
    "\n",
    "#     seg_score = []\n",
    "#     for seg_idx in range(n_segs):\n",
    "#         start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
    "#         scores = frame_scores[start:end]\n",
    "#         seg_score.append(float(scores.mean()))\n",
    "\n",
    "    seg_score = ypred\n",
    "\n",
    "    limits = int(math.floor(n_frames * proportion))\n",
    "\n",
    "    if method == 'knapsack':\n",
    "        #picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
    "        picks = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
    "    elif method == 'rank':\n",
    "        order = np.argsort(seg_score)[::-1].tolist()\n",
    "        picks = []\n",
    "        total_len = 0\n",
    "        for i in order:\n",
    "            if total_len + nfps[i] < limits:\n",
    "                picks.append(i)\n",
    "                total_len += nfps[i]\n",
    "    else:\n",
    "        raise KeyError(\"Unknown method {}\".format(method))\n",
    "\n",
    "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
    "    for seg_idx in range(n_segs):\n",
    "        nf = nfps[seg_idx]\n",
    "        if seg_idx in picks:\n",
    "            tmp = np.ones((nf), dtype=np.float32)\n",
    "        else:\n",
    "            tmp = np.zeros((nf), dtype=np.float32)\n",
    "        summary = np.concatenate((summary, tmp))\n",
    "\n",
    "    summary = np.delete(summary, 0) # delete the first element\n",
    "    return summary\n",
    "\n",
    "\n",
    "def evaluate_usersummary(machine_summary, user_summary, eval_metric='avg'):\n",
    "    \"\"\"Compare machine summary with user summary (keyshot-based).\n",
    "    Args:\n",
    "    --------------------------------\n",
    "    machine_summary and user_summary should be binary vectors of ndarray type.\n",
    "    eval_metric = {'avg', 'max'}\n",
    "    'avg' averages results of comparing multiple human summaries.\n",
    "    'max' takes the maximum (best) out of multiple comparisons.\n",
    "    \"\"\"\n",
    "    machine_summary = machine_summary.astype(np.float32)\n",
    "    user_summary = user_summary.astype(np.float32)\n",
    "    n_users,n_frames = user_summary.shape\n",
    "\n",
    "    # binarization\n",
    "    machine_summary[machine_summary > 0] = 1\n",
    "    user_summary[user_summary > 0] = 1\n",
    "\n",
    "    if len(machine_summary) > n_frames:\n",
    "        machine_summary = machine_summary[:n_frames]\n",
    "    elif len(machine_summary) < n_frames:\n",
    "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
    "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
    "\n",
    "    f_scores = []\n",
    "    prec_arr = []\n",
    "    rec_arr = []\n",
    "\n",
    "    for user_idx in range(n_users):\n",
    "        gt_summary = user_summary[user_idx,:]\n",
    "        overlap_duration = (machine_summary * gt_summary).sum()\n",
    "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
    "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
    "        if precision == 0 and recall == 0:\n",
    "            f_score = 0.\n",
    "        else:\n",
    "            f_score = (2 * precision * recall) / (precision + recall)\n",
    "        f_scores.append(f_score)\n",
    "        prec_arr.append(precision)\n",
    "        rec_arr.append(recall)\n",
    "\n",
    "    if eval_metric == 'avg':\n",
    "        final_f_score = np.mean(f_scores)\n",
    "        final_prec = np.mean(prec_arr)\n",
    "        final_rec = np.mean(rec_arr)\n",
    "    elif eval_metric == 'max':\n",
    "        final_f_score = np.max(f_scores)\n",
    "        max_idx = np.argmax(f_scores)\n",
    "        final_prec = prec_arr[max_idx]\n",
    "        final_rec = rec_arr[max_idx]\n",
    "    \n",
    "    return final_f_score, final_prec, final_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec52299-c626-4107-afcb-4b3053c6db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gtsummary(machine_summary, gt_summary):\n",
    "    \n",
    "    machine_summary = machine_summary.astype(np.float32)\n",
    "    user_summary = gt_summary\n",
    "\n",
    "    # binarization\n",
    "    machine_summary[machine_summary > 0] = 1\n",
    "    gt_summary[gt_summary > 0] = 1\n",
    "    n_frames = gt_summary.shape[0]\n",
    "\n",
    "    if len(machine_summary) > n_frames:\n",
    "        machine_summary = machine_summary[:n_frames]\n",
    "    elif len(machine_summary) < n_frames:\n",
    "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
    "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
    "\n",
    "    overlap_duration = (machine_summary * gt_summary).sum()\n",
    "    precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
    "    recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
    "    if precision == 0 and recall == 0:\n",
    "        f_score = 0.\n",
    "    else:\n",
    "        f_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return f_score, precision, recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf147d9-45af-4a83-ae5e-79fef04e592a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "298da162-c1d0-4231-af02-4520cc5ad1be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HParameters:\n",
    "        \n",
    "    def __init__(self, args):\n",
    "        \n",
    "        self.verbose = args['verbose']\n",
    "        self.use_cuda = args['use_cuda']\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        else: \n",
    "            self.device = torch.device('cpu')\n",
    "\n",
    "        self.max_summary_length = args['max_summary_length']\n",
    "\n",
    "        self.l2_req = 0.00001\n",
    "        self.lr_epochs = [0]\n",
    "        self.lr = [0.00005]\n",
    "        self.epochs_max = args['epochs']\n",
    "        self.train_batch_size = args['train_batch_size']\n",
    "\n",
    "        self.dataset=args['dataset']\n",
    "        self.scene_segs = args['Scene_segments']\n",
    "        self.results_path = args['results_path']\n",
    "        self.num_splits = args['num_splits']\n",
    "        self.split_file = args['split_file']\n",
    "        self.train_percent = args['train_percent']\n",
    "        self.model_folder = args['model_folder']+'/'\n",
    "        \n",
    "        if 'model_path' in args:\n",
    "            self.model_path = args['model_path']\n",
    "        else:\n",
    "            self.model_path = None\n",
    "        \n",
    "        with open(self.results_path, \"w\") as f:\n",
    "            f.write('Epoch\\tTrainLoss\\tValLoss\\n')\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    def create_split(self):\n",
    "        print(\"Loading dataset from {}\".format(self.dataset))\n",
    "        \n",
    "        with h5py.File(self.dataset, 'r') as dataset:\n",
    "            keys = dataset.keys()\n",
    "            num_videos = len(keys)\n",
    "            num_train = int(math.ceil(num_videos * self.train_percent))\n",
    "            num_test = num_videos - num_train\n",
    "\n",
    "            print(\"Split breakdown: # total videos {}. # train videos {}. # test videos {}\".format(num_videos, num_train, num_test))\n",
    "            splits = []\n",
    "\n",
    "            for split_idx in range(self.num_splits):\n",
    "                train_keys, test_keys = split_random(keys, num_videos, num_train)\n",
    "                splits.append({\n",
    "                    'train_keys': train_keys,\n",
    "                    'test_keys': test_keys,\n",
    "                    })\n",
    "\n",
    "            # saveto = osp.join(self.split_file)\n",
    "            write_json(splits, self.split_file)\n",
    "            print(\"Splits saved to {}\".format(self.split_file))\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        vars = [attr for attr in dir(self) if not callable(getattr(self,attr)) and not (attr.startswith(\"__\") or attr.startswith(\"_\"))]\n",
    "\n",
    "        info_str = ''\n",
    "        for i, var in enumerate(vars):\n",
    "            val = getattr(self, var)\n",
    "            if isinstance(val, Variable):\n",
    "                val = val.data.cpu().numpy().tolist()[0]\n",
    "            info_str += '['+str(i)+'] '+var+': '+str(val)+'\\n'\n",
    "\n",
    "        return info_str\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ec2db-e6eb-408f-9442-1e861711badc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "301dbd28-1415-4409-bb4d-821d0a41f72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, hps: HParameters):\n",
    "        print(\"Initializing HMT model and optimizer...\")\n",
    "        self.hps = hps\n",
    "        self.model = Trirar()\n",
    "        self.verbose = True\n",
    "        self.criterion = nn.MSELoss().to(self.hps.device)\n",
    "        self.show_every = 1\n",
    "        self.init_model()\n",
    "        \n",
    "\n",
    "        \n",
    "    def init_model(self):\n",
    "        if self.hps.model_path:\n",
    "            self.model.load_state_dict(torch.load(self.hps.model_path, map_location=lambda storage, loc: storage))\n",
    "            print('loading pretrained model from', self.hps.model_path)\n",
    "        else:\n",
    "            self.model.eval()\n",
    "            self.model.apply(weights_init)\n",
    "\n",
    "        self.model.to(self.hps.device)\n",
    "   \n",
    "    def train(self, train_keys):\n",
    "        losses=[]\n",
    "        \n",
    "        pbar = tqdm(total=len(train_keys), position=0, leave=True)\n",
    "        \n",
    "        for i, key in enumerate(train_keys[:2]):\n",
    "            with h5py.File(self.hps.dataset) as d, h5py.File(self.hps.scene_segs) as scnseg:\n",
    "                vid_feats= d[key]['features'][...]\n",
    "                aud_feats= d[key]['aud_feats'][...]\n",
    "                boundaries = d[key]['fchange_points'][...]\n",
    "                scn_boundaries = scnseg[key]['scene_points'][...]\n",
    "                n_frames = d[key]['n_frames'][()]\n",
    "                target = d[key]['gt_score'][...]\n",
    "                \n",
    "                # target = target.astype(float)\n",
    "                \n",
    "            vid_feats = torch.from_numpy(vid_feats).unsqueeze(0).float().to(self.hps.device)\n",
    "            aud_feats = torch.from_numpy(aud_feats).unsqueeze(0).float().to(self.hps.device)\n",
    "            target = torch.tensor(target).float().to(self.hps.device)\n",
    "            boundaries = torch.tensor(boundaries).to(self.hps.device)\n",
    "            scn_boundaries = torch.tensor(scn_boundaries).to(self.hps.device)\n",
    "\n",
    "            # Min-Max Normalize frame scores\n",
    "            target -= target.min()\n",
    "            target /= target.max()\n",
    "\n",
    "\n",
    "            # if self.hps.use_cuda:\n",
    "            #     vid_feats, aud_feats, target, boundaries  = vid_feats, aud_feats.float().to(device), target.float().to(device), boundaries.to(device)\n",
    "\n",
    "            # seq_len = seq.shape[1]\n",
    "            # print('Video key:',key, 'video and audio feat shape:', vid_feats.shape, aud_feats.shape)\n",
    "            batch_size = torch.tensor(self.hps.train_batch_size).to(self.hps.device)\n",
    "            P = self.model(vid_feats,aud_feats, boundaries, scn_boundaries, batch_size)\n",
    "            P = P.reshape(-1)\n",
    "            # print(P)\n",
    "            P_frames = get_frame_probs(P, boundaries, n_frames, self.hps.device)\n",
    "\n",
    "            loss_att = 0\n",
    "            loss = self.criterion(P_frames[:len(target)], target)\n",
    "            # print('Loss:', loss)\n",
    "            loss = loss + loss_att\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(float(loss))\n",
    "            \n",
    "            pbar.update(1)\n",
    "            # pbar.set_description(f\"Loss:{loss.item()}\")\n",
    "            pbar.set_postfix({'Loss': loss.item()})\n",
    "            del(boundaries)\n",
    "            del(batch_size)\n",
    "            \n",
    "            \n",
    "            \n",
    "        return np.mean(np.array(losses))\n",
    "\n",
    "    \n",
    "    def video_fscore(self, machine_summary_activations, test_keys, metric='tvsum', att_vecs=None):\n",
    "        eval_metric = 'avg' if metric == 'tvsum' else 'max'\n",
    "\n",
    "        # if results_filename is not None:\n",
    "        #     h5_res = h5py.File(results_filename, 'w')\n",
    "\n",
    "        fus,fgs = [],[]\n",
    "        video_scores = []\n",
    "        for key_idx, key in enumerate(test_keys):\n",
    "            \n",
    "            probs = machine_summary_activations[key]\n",
    "\n",
    "\n",
    "            with h5py.File(self.hps.dataset,'r') as d:\n",
    "                cps = d[key]['change_points'][...]\n",
    "                num_frames = d[key]['n_frames'][()]\n",
    "                nfps = d[key]['n_frame_per_seg'][...].tolist()\n",
    "                positions = d[key]['picks'][...]\n",
    "                user_summary = d[key]['user_summary'][...]\n",
    "                gt_summary = d[key]['gt_summary'][...]\n",
    "\n",
    "            machine_summary = generate_summary(probs, cps, num_frames, nfps, positions)\n",
    "            fu, _, _ = evaluate_usersummary(machine_summary, user_summary, eval_metric)\n",
    "            fg, _, _ = evaluate_gtsummary(machine_summary, gt_summary)\n",
    "            fus.append(fu)\n",
    "            fgs.append(fg)\n",
    "\n",
    "            # Reporting & logging\n",
    "            video_scores.append([key_idx + 1, key, \"{:.1%}\".format(fu), \"{:.1%}\".format(fg)])\n",
    "            # video_gt_scores.append([key_idx + 1, key, \"{:.1%}\".format(fg)])\n",
    "            \n",
    "        mean_fu = np.mean(fus)\n",
    "        mean_fg = np.mean(fgs)\n",
    "        \n",
    "        return (mean_fu+mean_fg)/2, video_scores\n",
    "\n",
    "    def validate(self, test_keys, show=None):\n",
    "        self.model.eval()\n",
    "        summary = {}\n",
    "        valLoss = []\n",
    "        with torch.no_grad():\n",
    "            for i, key in enumerate(test_keys):\n",
    "                with h5py.File(self.hps.dataset) as d, h5py.File(self.hps.scene_segs) as scnseg:\n",
    "                    vid_feats = d[key]['features'][...]\n",
    "                    aud_feats= d[key]['aud_feats'][...]\n",
    "                    boundaries = d[key]['fchange_points'][...]\n",
    "                    scn_boundaries = scnseg[key]['scene_points'][...]\n",
    "                    n_frames = d[key]['n_frames'][()]\n",
    "                    target = d[key]['gt_score'][...]\n",
    "                    \n",
    "                vid_feats = torch.from_numpy(vid_feats).unsqueeze(0).float().to(self.hps.device)\n",
    "                aud_feats = torch.from_numpy(aud_feats).unsqueeze(0).float().to(self.hps.device)\n",
    "                boundaries = torch.tensor(boundaries).to(self.hps.device)\n",
    "                scn_boundaries = torch.tensor(scn_boundaries).to(self.hps.device)\n",
    "                target = torch.tensor(target).float().to(self.hps.device)\n",
    "\n",
    "                batch_size = torch.tensor(self.hps.train_batch_size).to(self.hps.device)\n",
    "                P = self.model(vid_feats,aud_feats, boundaries, scn_boundaries, batch_size)\n",
    "                P = P.reshape(-1)\n",
    "                P_frames = get_frame_probs(P, boundaries, n_frames, self.hps.device)\n",
    "                \n",
    "                # Min-Max Normalize frame scores\n",
    "                target -= target.min()\n",
    "                target /= target.max()\n",
    "                valLoss.append(self.criterion(P_frames[:len(target)], target))\n",
    "                \n",
    "                summary[key] = P.detach().cpu().numpy()\n",
    "                del(boundaries)\n",
    "                del(batch_size)\n",
    "\n",
    "\n",
    "        f_score, video_scores  = self.video_fscore(summary, test_keys)\n",
    "        \n",
    "        if show:\n",
    "            print('Average F-score: ', f_score)\n",
    "            scores = [[\"No.\", \"Video\", \"User F-score\", \"GT F-Score\"]] + video_scores\n",
    "            print_table(scores)\n",
    "            return\n",
    "            \n",
    "        return f_score, video_scores, np.mean(valLoss)\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        self.optimizer = torch.optim.Adam(parameters, lr=self.hps.lr[0], weight_decay=self.hps.l2_req)\n",
    "        \n",
    "        lr = self.hps.lr[0] \n",
    "        \n",
    "        f = open(hps.split_file)\n",
    "        splits = json.load(f)\n",
    "        n_folds = len(splits)\n",
    "        \n",
    "        print(\"Starting training...\")\n",
    "        for split in splits:\n",
    "            max_val_fscore = 0\n",
    "            max_val_fscore_epoch = 0\n",
    "            train_keys = split['train_keys']\n",
    "            test_keys = split['test_keys']\n",
    "\n",
    "            epoch_losses=[]\n",
    "            for epoch in range(self.hps.epochs_max):\n",
    "\n",
    "                print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(self.hps.epochs_max)), end='')\n",
    "                with open(self.hps.results_path, \"a\") as f:\n",
    "                    f.write(str(epoch)+'\\t')\n",
    "                    \n",
    "                self.model.train()\n",
    "\n",
    "                random.shuffle(train_keys) \n",
    "                loss = self.train(train_keys)\n",
    "                epoch_losses.append(np.mean(loss))\n",
    "                \n",
    "                print(f'Epoch:{epoch}, Loss:{loss}')\n",
    "                with open(self.hps.results_path, \"a\") as f:\n",
    "                    f.write(str(loss)+'\\t')\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Evaluate train/test dataset\n",
    "                val_fscore, video_scores, valLoss = self.validate(test_keys)\n",
    "                with open(self.hps.results_path, \"a\") as f:\n",
    "                    f.write(str(valLoss)+'\\n')\n",
    "                \n",
    "        \n",
    "                if max_val_fscore < val_fscore:\n",
    "                    max_val_fscore = val_fscore\n",
    "                    max_val_fscore_epoch = epoch\n",
    "\n",
    "                self.save_model(self.hps.model_folder, f'model@epc{epoch%6}')\n",
    "\n",
    "\n",
    "            avg_loss = np.array(epoch_losses)\n",
    "            print(\"   Avg. Train loss: {0:.05f}\".format(np.mean(np.array(epoch_losses))), end='')\n",
    "            print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore  ))\n",
    "\n",
    "            \n",
    "            if self.verbose:\n",
    "                video_scores = [[\"No.\", \"Video\", \"User F-score\", \"GT F-Score\"]] + video_scores\n",
    "                print_table(video_scores)\n",
    "             \n",
    "\n",
    "        # return max_val_fscore, max_val_fscore_epoch\n",
    "        return\n",
    "    \n",
    "    def save_model(self, path, name):\n",
    "        # Save model weights\n",
    "        filename = name+'.pt.tar'\n",
    "        torch.save(self.model.state_dict(), os.path.join(path, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933537a9-9009-4d10-b65b-3d5b8a5f2af1",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6ee8605c-fa7c-4196-9abd-aadf592dfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "    'results_path':'results/training_results.txt',\n",
    "    'num_splits':5,\n",
    "    'train_batch_size':5,\n",
    "    'split_file':'splits/test_split1.json',\n",
    "    'dataset': '../../Preprocessing/extracted_features/normal/TVSum05s.h5',\n",
    "    'Scene_segments': '../../Segmentation/Transnet/transnet_segments/tvsumSegs05s.h5',\n",
    "    'model_folder': 'models',\n",
    "    # 'model_path':'models/model@epc0.pt.tar',\n",
    "    'train_batch_size':5,\n",
    "    'epochs': 50,\n",
    "    'train_percent':0.8,\n",
    "    'verbose':True,\n",
    "    'use_cuda' : False,\n",
    "    'cuda_device': None,\n",
    "    'max_summary_length': 0.15\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8ae8df64-01ae-4755-a6e2-39f814bb4035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ../../Preprocessing/extracted_features/normal/TVSum05s.h5\n",
      "Split breakdown: # total videos 50. # train videos 40. # test videos 10\n",
      "Splits saved to splits/test_split1.json\n"
     ]
    }
   ],
   "source": [
    "hps = HParameters(args)\n",
    "# hps.load_from_args(args.__dict__)\n",
    "hps.create_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb419763-e8a9-4929-b0fa-676846e31fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing HMT model and optimizer...\n",
      "Starting training...\n",
      "Epoch: 0/50  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:02<00:49,  1.30s/it, Loss=0.165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Loss:0.18216563016176224\n",
      "Epoch: 1/50  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:02<00:48,  1.26s/it, Loss=0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.1481345035135746\n",
      "Epoch: 2/50  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:01<00:24,  1.52it/s, Loss=0.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Loss:0.216939277946949\n",
      "Epoch: 3/50  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(hps)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [108]\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    187\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(train_keys) \n\u001b[1;32m--> 188\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(loss))\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [108]\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, train_keys)\u001b[0m\n\u001b[0;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m+\u001b[39m loss_att\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 66\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     68\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(hps)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76889f2b-1b5c-49ac-95b1-4201d7f84615",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(hps.split_file)\n",
    "splits = json.load(f)\n",
    "n_folds = len(splits)\n",
    "test_keys = splits[0]['test_keys']\n",
    "trainer.validate(test_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da158ed4-0f4e-436e-a7ad-d1fa583fdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(hps.split_file)\n",
    "splits = json.load(f)\n",
    "n_folds = len(splits)\n",
    "test_keys = splits[0]['test_keys']\n",
    "trainer.validate(test_keys, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e128302-6514-4aec-9fe2-22af48da162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0cc69-1791-4d60-8568-2d8c9711763b",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff49d83-0dff-42e3-9bed-9cdf6bd7c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1,2,5,3], [1,2,5,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cdda41-0fd2-43da-84b7-8c8bfb0b9cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4f93bf78-867e-4606-a156-a8ca17094125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/myfile3.txt\", \"a\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d3c48-30d4-40b1-9beb-deb9e1f3e0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854372b-71ef-415c-b2ac-ae027fbe4151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd131482-a438-4aea-9c87-6ea34e8b013b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31daa459-f023-42a6-bdc4-9a525fe7419e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb034b0-45ed-4404-b508-370507b47224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
